\Opensolutionfile{solution_file}[sols_chap_06]
% в квадратных скобках фактическое имя файла


\section{Математическое ожидание - интеграл Лебега}
\subsection{Интеграл Лебега}

Математическое ожидание - это синоним интеграла Лебега. Единственное отличие в том, что интеграл Лебега иногда считают относительно произвольной меры, а математическое ожидание - только относительно вероятности.

Нам потребуется строгое определение математического ожидания, подходящее для любой случайной величины. Мы будем строить математическое ожидание пошагово. Начнем с простых случайных величин. Затем рассмотрим произвольные неотрицательные, затем действительные. И, когда это требуется, комплексные.

Итак, перед нами четыре объекта:
$\Omega$ - множество исходов
$\F$ - \s-алгебра событий
$P$ - вероятность, определенная для событий из $\F$
$X$ - случайная величина, измеримая относительно $\F$
Сразу уточним, что все рассматриваемые случайные величины должны быть измеримы относительно $\F$.

\begin{mydef}
Случайная величина $X$ называется простой, если принимает конечное число значений.
\end{mydef}


Если случайная величина простая, то ее можно представить в виде: $X=\sum_{i}^{n}x_{i}1_{A_{i}}$, где $A_{i}$ не пересекаются. Таких представлений может быть несколько (можно множество $A_{1}$, где $X$ равна, скажем 5, разбить на два подмножества).


Шаг 1. Простая неотрицательная случайная величина.

\begin{mydef}
Пусть $X$ - простая неотрицательная случайная величина, т.е. $X=\sum_{i=1}^{n}x_{i}1_{A_{i}}$. Интегралом Лебега по мере $P$ (или математическим ожиданием) называется число
\begin{equation}
\E(X):=\int X dP:=\sum_{i=1}^{n}x_{i}\P(A_{i})
\end{equation}
\end{mydef}

В определении неявно задействована измеримость. Вероятность $P$ определена только для событий из некой \s-алгебры \F, поэтому чтобы $\P(A_{i})$ существовали необходимо, чтобы случайная величина $X$ была измерима относительно этой \s-алгебры \F. Легко заметить, что определение корректно, т.к. не зависит от выбранного разбиения.


Кроме того, выполняются следующие свойства.

Если $X$, $Y$ - простые неотрицательные случайные величины и $a\geq 0$ - константа, то:

1. $\E(X+Y)=\E(X)+\E(Y)$.

2. $\E(aX)=a\E(X)$.

3. Если $X\geq Y$, то $\E(X)\geq \E(Y)$.


Шаг 2. Произвольная неотрицательная случайная величина.

\begin{mydef}
Пусть $X$ - произвольная неотрицательная случайная величина. Интегралом Лебега по мере $P$ (или математическим ожиданием) называется величина
\begin{equation}
\E(X):=\int X dP:=\sup_{Z\leq X, Z-simple}  \E(Z)
\end{equation}
\end{mydef}

Т.е. мы перебираем все простые случайные величины $Z$, не превосходящие $X$ и выбираем наибольшее из получающихся математических ожиданий. При этом нужно отметить, что в результате может получится уже не число, а плюс бесконечность. Также заметим, что новое определение не противоречит старому, т.к. если изначально $X$ - простая, то взяв $Z:=X$ мы получим старое значение математического ожидания, а больше получить невозможно в силу неравенства (\ldots ).


Все те же свойства:


Шаг 3. Произвольная случайная величина.

Любую случайную величину $X$ всегда можно представить в виде $X=X^{+}-X^{-}$, где $X^{+}=\max\{X,0\}$ - неотрицательная часть $X$, а $X^{-}=-\min\{X,0\}$ - неположительная часть $X$, домноженная на (-1). Величины $X^{+}$ и $X^{-}$ являются неотрицательными, а для неотрицательных у нас уже мат. ожидание придумано.

Картинка [\ldots ]

\begin{mydef}
Пусть $X$ - произвольная случайная величина. Интегралом Лебега по мере $P$ (или математическим ожиданием) называется величина
\begin{equation}
\E(X):=\int X dP:=\E(X^{+})-\E(X^{-})
\end{equation},

\end{mydef}




PE1.

PE2.


PE3. Если $X\geq 0$, то $\E(X)\geq 0$.

PE4. Если $X\geq 0$ и $\E(X)=0$, то $\P(X=0)=1$. (часто используется)

PE5. Если $X\geq 0$ и $\E(X)<\infty$, то $\P(X=\infty)=0$.




Обобщение для комплексных случайных величин!




\subsection{MCT, DCT, Fatou's lemma}

\begin{myth}
Если:

1. $X_{n}$ - неубывающая последовательность неотрицательных случайных величин измеримых относительно \F, $X_{1}\leq X_{2}\leq X_{3}\leq \ldots $

2. $\lim X_{n}=X$

То:

1. $X$ - измерима относительно $\F$

2. $\lim \E(X_{n})=\E(X)$
\end{myth}

Теорема учитывает случай, когда предел с обеих сторон равен плюс бесконечности.

\begin{proof}
Во-первых, заметим, что $\E(X_{n})\leq \E(X_{n+1})$. Т.е. предел слева обязательно существует, хотя возможно и равен плюс бесконечности.

Случай 1. Среди $X_{n}$ есть такая величина $X_{k}$, что $\E(X_{k})=\infty$.

Если $\E(X_{k})=\infty$, то для любого числа $M$ найдется такая простая случайная величина $S$, что $S\leq X_{k}$, но $\E(S)>M$. Замечаем, что $X\geq X_{k}\geq S$, а значит, $\E(X)\geq \E(S)>M$. Но $M$ произвольное число, значит $\E(X)=\infty$.

Случай 2. Все $\E(X_{n})$ конечны, но $\E(X_{n})\to\infty$.


Случай 3. Все $\E(X_{n})$ конечны, и $\E(X_{n})\to const$.

\end{proof}




\begin{myth}
Если:

1. Последовательность $X_{n}$ ограничена интегрируемой случайной величиной $Y$, т.е $|X_{n}|\leq Y$ и $\E(Y)\infty$.

2. $\lim X_{n}=X$

То:

$\lim \E(X_{n})=\E(X)$

\end{myth}
\begin{proof}

\end{proof}




Если применить лемму Фату к индикаторам, то получается лемма Фату для вероятностей.



Добавить Витали (?) Vitali convergence theorem





\subsection{Неравенства, леммы Бореля Кантелли}

Еще раз про леммы Бореля-Кантелли.

Первая лемма Бореля-Кантелли: если сумма вероятностей $A_{i}$ конечна, то вероятность того, что произойдет бесконечное количество $A_{i}$ равна нулю. теперь можно дать другое прочтение этой формуле. Пусть $N$ - количество произошедших $A_{i}$, и случайная величина $N$ может принимать значение $+\infty$. Если среднее значение $N$ конечно, то вероятность того, что $N=\infty$ равна нулю.

\begin{myth} Если $\sum \P(A_{i})<\infty$, то $\P(\limsup A_{i})=0$.
\end{myth}
\begin{proof} $\E(N)=\E(\sum_{i} 1_{A_{i}})$. Применяя MCT получаем, что $\E(N)=\sum \E(1_{A_{i}})=\sum \P(A_{i})<\infty$. А значит (используя PE5) и $\P(N=\infty)=0$.
\end{proof}
Вторая лемма Бореля-Кантелли: если $A_{i}$ независимы (или отрицательно коррелированы) и сумма вероятностей $A_{i}$ «велика» (равна бесконечности), то вероятность того, что произойдет бесконечное количество $A_{i}$  равна 1. Обобщение на отрицательно зависимые случайные величины заимстовано из \cite{ross:scp}

(самое время сделать упр. про $Cov(1_{A},1_{B})=0$ <> независимость)

\begin{myth} Если события $A_{i}$ независимы или неположительно коррелированы ($Cov(1_{A_{i}},1_{A_{j}})\leq 0$ для $\forall i,j$) и $\sum \P(A_{i})=\infty$, то $\P(\limsup A_{i})=1$.
\end{myth}
\begin{proof} Пусть $N_{k}$ - число произошедших событий среди первых $k$ событий, $N_{k}=1_{A_{1}}+1_{A_{2}}+\ldots +1_{A_{k}}$.

Шаг 1. $Var(N_{k})\leq \E(N_{k})$: $Var(N_{k})\leq \sum Var(1_{A_{i}})$ (т.к. ковариация либо нулевая, либо отрицательная), $\sum Var(1_{A_{i}})=\sum \P(A_{i})(1-\P(A_{i}))\leq \sum \P(A_{i}) =\E(N_{k})$.

Шаг 2. Рассмотрим произвольное число $x<\E(N_{k})$. Для такого $x$: $\P(N_{k}<x)=\P(\E(N_{k})-N_{k}>\E(N_{k})-x)\leq \P(|\E(N_{k})-N_{k}|>\E(N_{k})-x)\leq \frac{Var(N_{k})}{(\E(N_{k})-x)^2}\leq \frac{\E(N_{k})}{(\E(N_{k})-x)^2}$.

Шаг 3. Рассмотрим произвольное число $x$. В силу того, что $\E(N_{k})\to \E(N)=\infty$, наступит такой момент, что неравенство из шага 2 начнет работать. А значит $\lim_{k\to\infty} \P(N_{k}<x)=0$. Но, $\P(N<x)\leq \P(N_{k}<x)$, значит для $\forall x$, вероятность $\P(N<x)=0$.

Шаг 4. Для множеств действует предел $\lim (N<k)=N<\infty$, вероятность непрерывна,  а значит $\P(N<\infty)=0$.
\end{proof}


Неравенство Чебышева (Маркова). $\P(|X|\geq a)\leq \frac{\E(|X|)}{a}$.
\begin{proof}
\end{proof}
Неравенство Йенсена. Если $f:\R\to\R$ - выпуклая функция (уточним, выпуклая вниз, как, например, $f(t)=t^{2}$), то $\E(f(X))\geq f(\E(X))$.
\begin{proof}
\end{proof}
Мне тут попалось малоизвестное забавное неравенство. Будем его популяризировать!

Неравенство «Раз-два-три»! Если $X$ и $Y$ независимые случайные величины, то $\E(|X-Y|<2)<3\P(|X-Y|<1)$.

Noga Alon, The 123 theorem and its extensions. Или в упражнения (да, оно дальше не используется)?






\subsection{Производная Радона-Никодима}


Оказывается, если из одной вероятности легко получить новую!

\begin{myth} Если $X$-неотрицательная случайная величина и $\E(X)>0$, то функция $Q:\F\to [0;1]$, определяемая по формуле: $Q(A)=\frac{\E(1_{A}X)}{\E(X)}$ является вероятностью.
\end{myth}
\begin{proof}
Легко убедиться, что $Q(\emptyset)=\frac{\E(0)}{\E(X)}=0$ и $Q(\Omega)=\frac{\E(X)}{\E(X)}=1$. Осталось проверить счетную аддитивность (аксиому M2 в определении меры).

Пусть $A_{i}$ - попарно непересекающиеся события. Определим $Y_{n}=\sum_{i=1}^{n}1_{A_{i}}X$. Последовательность $X_{n}$ монотонная и поточечно сходится к $Y=\sum_{i=1}^{\infty}1_{A_{i}}X$. Согласно MCT (\ldots ) $\E(Y)=\lim \E(X_{n})=\lim \sum_{i=1}{n} \E(1_{A_{i}}X)=\sum_{i=1}{\infty} \E(1_{A_{i}}X)$. Разделив обе части на $\E(X)$ получаем $Q(\cup A_{i})=\sum Q(A_{i})$.
\end{proof}

\begin{myex} Пусть (табличка), $Q(A)=\frac{\E(1_{A}X)}{\E(X)}$
\ldots
Найдите $Q(Y>0)$, $E_{Q}(Y)$
\end{myex}

\begin{myth} Для новой вероятности $Q(A)=\frac{\E(1_{A}X)}{\E(X)}$ новое математическое ожидание будет считаться по формуле $E_{Q}(Y)=\frac{\E(XY)}{\E(X)}$.
\end{myth}
\begin{proof} Доказательство использует стандартный пошаговый метод.
Сначала для простых $Y$.

Теперь для неотрицательных $Y$.

Теперь для произвольных $Y$.
\end{proof}

\begin{myex} Здесь будет дискретный пример.
\end{myex}


\begin{mydef} Вероятность $Q$ называется \indef{абсолютно непрерывной} по отношению к вероятности $P$, если из условия $\P(A)=0$ всегда следует, что $Q(A)=0$. Обозначается абсолютная непрерывность $P»Q$.
\end{mydef}
\begin{myex} Пусть $\Omega=[0;1]$, $\F=\B[0;1]$, $\lambda$ - классическая мера Лебега на $[0;1]$. \ldots  Чтобы была абсолютная и второй пример, чтобы не было.
\end{myex}



Оказывается иногда верно и обратное, а именно:
\begin{myth} Если $P$ и $Q$ - две вероятности, $P»Q$, то существует единственная почти-наверное случайная величина $X$, такая что $E_{P}(X)=1$ и $Q(A)=E_{P}(X1_{A})$.
\end{myth}
\begin{proof} Доказательство существования - в аппендикс (?)
Нетрудно доказать, что $E_{P}(X)=E_{P}(X\cdot 1_{\Omega})=Q(\Omega)=1$. Легко доказать и единственность:
Пусть $X$ и $Y$ две функции, удовлетворяющие теореме, тогда $Q(X>Y)=E_{P}(X\cdot 1_{X>Y})=E_{P}(Y\cdot 1_{X>Y})$. Отсюда, $E_{P}((X-Y)1_{X-Y>0})=0$. Но, $(X-Y)1_{X-Y>0}$ - неотрицательная случайная величина, значит $\P((X-Y)1_{X-Y>0}>0)=0$ и $\P(X-Y>0)=0$. Из симметрии $\P(Y-X>0)=0$ и, наконец, $\P(X=Y)=1$.
\end{proof}

\begin{myex} (или упр.) найдите производную радона-никодима - дискретный случай
\end{myex}

\begin{myex} Пусть $\Omega=[0;1]$,  (упр.?) - производная радона-никодима непрер. случай
\end{myex}




\subsection{Пространство L2 и его геометрия}


\begin{mydef} Пусть $X$ - случайная величина и $p\geq 1$. Определим $||X||_{p}:=(\E(|X|^{p}))^{1/p}$.
\end{mydef}
Это определение допускает, что $||X||_{p}$ может равняться $+\infty$.

Упражнение. приведите пример $X$, такой что $||X||_{1}<\infty$, а $||X||_{2}=\infty$.

\begin{mydef} Пространством $L^{p}(\Omega,\F,P)$ назовем множество \F-измеримых случайных величин, таких, что $||X||_{p}<+\infty$.
\end{mydef}
Когда понятно о каких \F и $P$ идет речь мы будем сокращать обозначение $L^{p}(\Omega,\F,P)$ до $L^{p}(\Omega)$ и даже до $L^{p}$.

\begin{myth} Пространство $L^{p}$ является линейный пространством над $\R$. Если $X\in L^{p}$, $Y\in L^{p}$ и $a\in \R$, то $X+Y\in L^{p}$ и $aX\in L^{p}$.
\end{myth}
\begin{proof}
\end{proof}
\begin{myth} Если $1\leq p\leq q$, то $L^{q}\subset L^{p}$
\end{myth}
\begin{proof}
\end{proof}
Holder, Minkowski


Чуть позже (\ldots ) мы докажем полноту пространства $L^{p}$.

Среди пространств $L^{p}$ наибольший интерес представляет для нас пространство $L^{2}$. Во-первых, потому, что именно в $L^{2}$ мы будем по началу определять интеграл Ито. Во-вторых, потому, что в $L^{2}$ есть красивая геометрия, даже две!

(вставка про геометрию)


\subsection{Сеанс связи с Землей}

Может показаться, что этот конспект - какой-то другой курс теории вероятностей. Формально определяется то, что раньше без всяких проблем и заморочек считалось. Осталось связать эти «два» курса, указав, что способ подсчета был верный.

Как до теории меры мы считали математической ожидание случайной величины или функции от нее?

Мы использовали функцию плотности $p(x)$ и брали обычный (Римановский) интеграл:

$\E(f(X))=\int_{-\infty}^{+\infty}f(x)p(x)dx$

Чтобы обосновать этот способ сначала напомним пару определений:

\begin{mydef} Функция $p(x)$ называется \indef{функцией плотности} случайной величины $X$, если\ldots
\end{mydef}
(дать два варианта? с борелевскими и с нормальными?)

\begin{mydef} Функция называется интегрируемой по Риману\ldots
\end{mydef}

Теоремы, связывающие:



\subsection{Еще задачи}



\Closesolutionfile{solution_file}
