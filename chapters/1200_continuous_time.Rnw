\Opensolutionfile{solution_file}[sols_chap_12]
% в квадратных скобках фактическое имя файла

\section{Процессы в непрерывном времени}

Начиная с этой главы читателю предстоит бороться с дополнительной трудностью - с меняющимися обозначениями. Почему? Потому, что писать $X_{t}$ (значение процесса в момент времени $t$) проще, чем писать $X(t)$, но иногда приходится иметь дело с последовательностями процессов, и тогда удобнее будет обозначение $X_{n}(t)$.


\subsection{Версии, непрерывность справа}


\subsection{Гауссовские процессы}


Гауссовский случайный процесс.
\begin{mydef} Случайный процесс $X_{t}$ называется гауссовским, если любой вектор $(X_{t_{1}},X_{t_{2}},\ldots ,X_{t_{k}})$ имеет многомерное нормальное распределение (возможно вырожденное).
\end{mydef}
Из определения ясно, что разные гауссовские процессы могут различаться математическим ожиданием, функцией $\mu(t)=\E(X_{t})$, и ковариационной функцией, $\gamma(s,t)=Cov(X_{t},X_{s})$. Важнее, конечно, ковариационная функция, т.к. простым преобразованием $Y_{t}=X_{t}-\E(X_{t})$ всегда можно добиться того, что математическое ожидание равно нулю.



\subsubsection*{Задачи}

\begin{problem}
\label{geometric sense of correlation}
Пусть величины $X$ и $Y$ имеют совместное нормальное распределение с нулевым средним, единичной дисперсией и корреляцией $\rho$. \\
a) Представьте $Y$ в виде $Y=aX+bZ$, так, чтобы $Z\sim N(0;1)$, а $Z$ и $X$ не были бы коррелированы. \\
б) Что представляет собой множество $X>0\cap Y>0$ в осях $(X,Z)$? \\
в) Чему равна вероятность $\P(XY>0)$? \\
г) Постройте график $\P(XY>0)$ как функции от $\rho$
\begin{sol}
a) $Y=\rho X+\sqrt{1-\rho^{2}} Z$ \\
б) Угол с градусной мерой $\theta=\pi/2+\arcsin(\rho)$ \\
в) $\P(XY>0)=\theta/\pi$
\end{sol}
\end{problem}

\begin{problem}
Пусть величины $X$, $Y$, $Z$ - имеют совместное нормальное распределение, с математическим ожиданием $0$ и некоей ковариационной матрицей $B$. \\
Как зависит от $B$ вероятность $\P(XYZ>0)$?
\begin{sol}
Никак. Если рассмотреть величины $-X$, $-Y$, $-Z$, то у них такое же математическое ожидание и такая же ковариационная матрица. Значит $\P(XYZ>0)=\P((-X)(-Y)(-Z)>0)$. Но эти вероятности в сумме дают 1, значит они равны по 0.5.
\end{sol}
\end{problem}



\subsection{Случайный процесс - это одна случайная величина}
\label{process_one_rv}


Буквально только что мы сказали, что случайный процесс - это набор случайных величин. Оказывается, что можно и иногда полезно рассматривать целый случайный процесс как \indef{одну} случайную величину. Вот как это можно сделать:

Для примера возьмем случайный процесс для $t\in[0;1]$. Случайным образом выберем траекторию, затем случайно (равномерно) выберем момент времени $t$. И вуаля, вместо целого процесса $X_{t}$ мы получили одну случайную величину $X$! При этом мы изменили пространство $\Omega$ на котором был задан случайный процесс $X_{t}$. А именно, новая случайная величина $X$ задана на множестве $\Omega'=\Omega\times [0;1]$. А вероятности считаются с помощью новой меры $P'=P\times \lambda$, где $\lambda$ - классическая мера Лебега, задающая равномерное распределение.

При такой интерпретации корректно говорить, например, о $P'(X<0.2)$ и о $\int_{\Omega'}XdP'=E'(X)$. Давайте попробуем на паре конкретных задач:

\begin{itemize}
\item Какой случайный процесс соответствует случайной величине $1_{\Omega'}$?

Очень просто! Для любого $w'=(w,t)$ значение $1_{\Omega'}(w')=1$, значит наш случайный процесс $X_{t}$ всегда равен 1 (на любой траектории и в любой момент времени).

\item Пусть $Y$ равномерная случайная величина на $[0;1]$, и $X_{t}=Y-t$, процесс определенный для $t\in[0;1]$. Нарисуйте несколько разных траекторий процесса $X_{t}$. Рассмотрев процесс как одну случайную величину, найдите $P'(X<0,2)$ и $E'(X)$.

Любая траектория начинается в точке $y\in[0;1]$ и с единичной скоростью убывает на отрезке $[0;1]$. Какова при заданном $y$ вероятность того, что выбрав случайную точку на отрезке $[0;1]$ мы получим ординату меньше 0,2? Если $y\leq 0.2$, то вероятность равна 1; если $y>0.2$, то вероятностью равна $(y-0,2)$. Находим искомую вероятность:
\begin{equation}
P'(X<0,2)=\P(Y<0.2)+\P(Y>0.2)\E(Y-0.2|Y>0.2)=0.2+0.8\cdot 0.4=0.52
\end{equation}

Переходим к $E'(X)$. При фиксированном $y\in[0;1]$ траектория с постоянной скоростью опускается с отметки $y$ до отметки $y-1$, поэтому при фиксированном $y$ средняя ордината равна $\frac{y+y-1}{2}=y-0.5$. Усредняя по $y$ получаем, что $E'(X)=\E(Y-0.5)=0$. Попутно отметим, что $E'(X)$ можно интерпретировать как среднюю площадь под траекторией процесса.
\end{itemize}

Если процесс задан на $[0;T]$ (или на $[0;\infty)$), то новая мера $P':=P\times\lambda$ не будет вероятностью (т.к. длина $\lambda([0;T])=T$). Но принципиально это ничего не меняет!

По прежнему можно будет считать выражения типа $P'(X<0.2)$. только это будет не «вероятность», а «средняя длина» множества $X<0.2$. Для каждой отдельно взятой траектории (для каждого $w$) можно посчитать длину множества $\{t|X_{t}(w)<0.2\}$, а поскольку на $\Omega$ задана вероятность $P$, то интеграл означает среднее значение этой длины:

\begin{equation}
P'(X<0.2)=\int_{\Omega'}1_{X<0.2}dP'=\int_{\Omega}\int_{[0;T]}1_{X<0.2}d\lambda dP=\E(\lambda(X<0.2)),
\end{equation}
при раскрытии интеграла $\int_{\Omega'}(\cdot)dP'$ мы воспользовались теоремой Фубини.

Обозначение $E'(X)$ не совсем корректно (оно использовалось бы, если бы $P'$ была вероятностью). Осталось обозначение с интегралом $\int_{\Omega'}XdP'$. Сохранилась и интерпретация:  $\int_{\Omega'}XdP'$ - средняя площадь под траекторией процесса:

\begin{equation}
\int_{\Omega'}XdP'=\int_{\Omega}\int_{[0;T]}Xd\lambda dP=\E(\int_{[0;T]}Xd\lambda)
\end{equation}

Для усвоения еще пара примеров:  упр.

Единственное, что мы не проверили - это измеримость. За кадром должна быть некая \s-алгебра $\F'$, относительно которой функция $X$ должна быть измеримой. Какая же?

Процесс $X_{t}$ определен на пространстве $(\Omega,\F,P)$ и все случайные величины $X_{t}$ являются $\F$ измеримыми.  Может еще присутствовать фильтрация $\F_{t}$ и процесс $X_{t}$ может быть адаптирован к ней, но сейчас это не обязательно. Новое множество исходов, $\Omega':=\Omega\times [0;T]$ - это обычное декартово произведение, т.е. множество всех пар вида $(w,x)$, где $w\in\Omega$, $x\in [0;T]$. Естественная $\s$-алгебра событий на нем - это $\F\times\lambda$, минимальная \s-алгебра порожденная декартовым произведением \s-алгебр $\F$ и $\B$, $\F\times\B:=\s((F,B)|F\in\F,B\in\B)$. Эта же \s-алгебра $\F\times [0;T]$ является областью определения меры $P'=P\times\lambda$.

\begin{mydef} Процесс $X_{t}$ на пространстве $(\Omega,\F,P)$ для $t\in[0;T]$ (также и для $t\in[0;\infty)$) называется \indef{измеримым}, если функция $X$ измерима относительно $\s$-алгебры $\F\times \B$.
\end{mydef}

Зачем нам важна измеримость функции $X$ относительно $\F\times\B$? Именно это условие является позволяет интегрировать и получать «хороший» результат:

\begin{myth} Если функция $X$ измерима относительно $\F\times\lambda$, то для любого $t\in [0;T]$ интеграл $$Y_{t}=\int_{0}^{t}X_{t}d\lambda$$ корректно определен и является $\F$-измеримой случайной величиной.
\end{myth}
\begin{proof}
\end{proof}

Сформулируйте и докажите теорему (\ldots ) для случая $t\in[0;\infty)$ (упр.)

Иногда оказывается желательным, чтобы $Y_{t}=\int_{0}^{t}X_{t}d\lambda$ был не только $\F$-измерим, но и $\F_{t}$-измерим. Это требует более сильных условий на $X_{t}$:

\begin{mydef} Процесс $X_{t}$ на пространстве $(\Omega,\{\F_{t}\},\F,P)$ для $t\in[0;T]$ (также и для $t\in[0;\infty)$) называется \indef{прогрессивно измеримым}, если для любого $t\in[0;T]$ (или, соответственно, $t\in[0;\infty)$) случайная величина $X$ измерима относительно $\s$-алгебры $\F_{t}\times \B$.
\end{mydef}
\begin{myth} Если процесс $X_{t}$ прогрессивно измерим на $(\Omega,\{\F_{t}\},\F,P)$, то интеграл $$Y_{t}=\int_{0}^{t}X_{t}d\lambda$$ корректно определен и является $\F_{t}$-измеримой случайной величиной.
\end{myth}
\begin{proof} Зафиксируем момент времени $t$, в качестве $\F$ берем $\F_{t}$ и получаем желаемое в силу теоремы (\ldots )
\end{proof}

Оказывается, что связь между адаптированностью $X_{t}$ к фильтрации $\F_{t}$  и измеримостью $X$ относительно $\F\times\lambda$ нетривиальная. Этому и посвящены два следующих примера:

\begin{myex} Процесс $X_{t}$ адаптирован к $\F_{t}$, но случайная величина $X$ не измерима относительно $\F\times\B$.
\end{myex}


\begin{myex} Процесс $X_{t}$ не адаптирован к $\F_{t}$, но случайная величина $X$ измерима относительно $\F\times\B$.
\end{myex}

Общая картина выглядит так:



Если процесс $X_{t}$ «хороший», то $X$ измерим даже если он не адаптирован:
\begin{myth}
Если каждая траектория процесса $X_{t}$ является непрерывной слева (или непрерывной справа), то процесс $X_{t}$ измерим.
\end{myth}
\begin{proof}

\end{proof}



Для любопытных приведем пример измеримого, но не прогрессивно измеримого процесса:



\subsection{Еще задачи}

\Closesolutionfile{solution_file}
