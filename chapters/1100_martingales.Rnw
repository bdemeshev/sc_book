\Opensolutionfile{solution_file}[sols_chap_11]
% в квадратных скобках фактическое имя файла

\section{Мартингалы в дискретном времени}
\subsection{О случайном блуждании}

Случайное блуждание - пожалуй, самый важный из дискретных случайных процессов. Броуновскому движению в непрерывном времени многие свойства случайного блуждания «перейдут по наследству». Поэтому мы достаточно подробно изучим симметричное случайное блуждание.

\begin{mydef}
Пусть $X_{i}$ - последовательность независимых случайных величин, равновероятно принимающих значение $+1$ или $(-1)$. Процесс $S_{n}=\sum_{i=1}^{n}X_{i}$ называется \indef{симметричным случайным блужданием}.
\end{mydef}

Графически $S_{n}$ - это координаты частицы, которая начав в нуле равновероятно смещается на один шаг влево или вправо.

Чтобы «почувствовать» некоторые свойства случайного блуждания мы ответим на несколько вопросов:
\begin{enumerate}
\item Пусть $a$ и $b$ - два натуральных числа. Какова вероятность того, что случайное блуждание никогда не достигнет ни точки $a$, ни точки $-b$? Какова вероятность того, что $S_{n}$ «коснется» точки $a$ раньше, чем точки $-b$?
\item Сколько шагов в среднем потребуется, чтобы достигнуть точки $1$?
\item Сколько шагов в среднем потребуется, чтобы достигнуть уровня $a$ или $-b$?
\item Какова вероятность того, что случайное блуждание посетит точку $a$?
\item Какова вероятность того, что случайное блуждание вернется в точку $0$?
\item Сколько раз в среднем случайное блуждание посетит точку $a$?
\item Сколько раз в среднем случайное блуждание посетит точку $a$ прежде чем впервые вернется в точку $0$?
\end{enumerate}

Попробуйте для начала ответить на эти вопросы устно, без вычислений, интуитивно. Запишите свои ответы и потом сравните с правильными. В этой главе мы ответим на эти вопросы не произнося слова «мартингал». Поехали!

\begin{enumerate}
\item Пусть $a$ и $b$ - два натуральных числа. Какова вероятность того, что случайное блуждание никогда не достигнет ни точки $a$, ни точки $-b$? Какова вероятность того, что $S_{n}$ «коснется» точки $a$ раньше, чем точки $-b$?

Предположим, что мы стартуем не в нуле, а в произвольной точке $ x\in\{-b,-b+1,\ldots , a\} $. Обозначим интересующую нас вероятность как $ p_{x} $. По определению, $ p_{a}=1 $ и $ p_{-b}=0 $. Для остальных $ x $ выполнено рекуррентное соотношение:

\[ p_{x}=0.5p_{x-1}+0.5p_{x+1} \]

Если разбить $ p_{x} $ на два одинаковых слагаемых $ p_{x}=0.5p_{x}+0.5p_{x} $, то мы получим

\[ p_{x}-p_{x-1}=p_{x+1}-p_{x} \]

Это означает, что $ p_{x} $ растет линейно с постоянной скоростью от $ p_{-b}=0 $ до $ p_{a}=1 $. В частности, $ p_{0}=\frac{b}{a+b} $.


\item Сколько шагов в среднем потребуется, чтобы достигнуть точки $1$?

Пусть $m$ - это интересующее нас мат. ожидание. Заметим, что оно очевидно больше 1 и, а-приори, нельзя исключать, что оно бесконечно.

После первого шага мы либо достигли точки $1$ (и нам потребовался один шаг), либо отошли еще дальше от точки $1$ и нам в среднем потребуется $m$ шагов, чтобы вернуться в $0$ и еще в среднем $m$ шагов, чтобы попасть в $1$. Итого:
\begin{equation}
m=0.5\cdot 1 + 0.5 (1 + 2m)
\end{equation}
Хм, решений у этого уравнения нет. Точнее есть, а именно, $m=+\infty$.

\item Сколько шагов в среднем потребуется, чтобы достигнуть уровня $a$ или $-b$?

Пусть $e_{k}$ - искомое количество ходов, при условии, что сейчас мы находимся в точке $k$. Краевые условия: $e_{a}=0$ и $e_{b}=0$. Разностное уравнение:
\begin{equation}
e_{k}=1+0.5e_{k-1}+0.5e_{k+1}
\end{equation}

Чтобы не мучится с методом неопределенных коэффициентов, который, конечно, сработает, мы поступим так. Заметим, что решение - квадратный трехчлен, обнуляющийся в $a$ и $b$. Значит, это что-то типа $e_{k}=-(k-a)(k+b)$. Проверяем, подходит. Находим, что $e_{0}=ab$.

\item Какова вероятность того, что случайное блуждание посетит точку $a$?

Для начала посчитаем вероятность когда-либо посетить точку $1$. Обозначим ее $p$.

После первого шага мы либо уже в точке $1$ с вероятностью $0.5$, либо отошли влево. Если мы отошли влево, то чтобы посетить когда-нибудь точку $1$ придется сначала когда-нибудь посетить точку $0$, а затем когда-нибудь точку $1$. Итого:
\begin{equation}
p=0.5\cdot 1 + 0.5 p^{2}
\end{equation}

Единственное решение этого уравнения $p=1$. По-честному, нужно еще доказать, что событие «процесс когда-нибудь достигнет точки 1» - это событие, чтобы не случилось так, что вероятность не определена.

Теперь рассмотрим произвольную точку $a$. Мы с вероятностью 1 когда-нибудь попадем из точки $0$ в точку $1$. Когда-нибудь с вероятностью 1 попадем из $1$ в $2$ и т.д. Значит с вероятностью $1$ когда-нибудь попадем в $a$.

\item Какова вероятность того, что случайное блуждание вернется в точку $0$?

После первого шага мы отойдем на единичку вправо (или влево). А потом с вероятностью 1 вернемся в $0$.

\item Сколько раз в среднем случайное блуждание посетит точку $a$?

C вероятностью 1 мы попадем в $ a $ хотя бы раз. Затем мы отойдем на единичку вправо или влево. И снова с вероятностью 1 попадем в $a$. Значит в среднем мы посетим $a$ бесконечное количество раз.

\item Сколько раз в среднем случайное блуждание посетит точку $a$ прежде чем впервые вернется в точку $0$?
\end{enumerate}






Задачи\ldots

Решите все указанные задачи для несимметричного случайного блуждания.










\subsection{Про «хвостовую» сигма-алгебру. Для опоздавших.}

Пусть кто-то подбрасывает монетку бесконечное количество раз. Раз за разом, скажем одно подбрасывание в минуту. Введем случайную величину $X_{i}$, которая будет равна 1, если в $i$-ый раз выпала решка и 0, если орел. Величины $X_{1}$, $X_{2}$, \ldots  - независимы и одинаково распределены.

Известно, что Вася (любитель подольше поспать) опоздал к началу эксперимента. Опоздал на неизвестное нам время. То есть он наблюдает значения $X_{i}$ только начиная с некоторого номера $T$.

Есть ли какой-то список событий, которые Вася различает вне зависимости от того, на сколько минут он опоздал?

Казалось бы ответ «нет». Ни про одну из $X_{i}$ нельзя быть уверенным в том, что она известна Васе. Он мог опоздать на 10 минут и не знать $X_{1}$, \ldots , $X_{9}$. А мог опоздать на 1000 минут и не знать значений $X_{1}$, \ldots , $X_{999}$.

Однако это не так! На сколько бы Вася не опоздал, он всегда сможет сказать, произошли ли события «начиная с некоторого момента были только орлы» или «орел сменялся на решку бесконечное количество раз».

Насколько бы Вася не опоздал он станет свидетелем целой кучи событий!

\begin{mydef} Пусть $\F_{n}'=\s(X_{n},X_{n+1},\ldots )$ - \s-алгебра событий различимых наблюдателем, пришедшем в момент времени $n$. \indef{Остаточной} \s-алгеброй называется \s-алгебра $\cap_{n} \F_{n}'$.
\end{mydef}
(упр) Приведите еще три примера событий, наблюдателем которых станет Вася, вне зависимости от величины опоздания.

Правда все события из этой \s-алгебры в каком-то смысле тривиальны и ради них не стоило и торопиться. Можно было не выходя из дома, сказать произойдут они или нет (почти наверное)!

\begin{myth}[Закон 0-1 Колмогорова] Если $X_{i}$ - последовательность независимых одинаково распределенных случайных величин, и $\mathcal{H}$ - остаточная \s-алгебра, то для любого события $H\in\mathcal{H}$ вероятность $\P(H)=0$ или $\P(H)=1$.
\end{myth}

\begin{proof}
\end{proof}

\begin{myex} Рассмотрим событие $A$ - «последовательность «Решка-Решка-Орел» встречается бесконечное количество раз». Это событие входит в остаточную \s-алгебру, поэтому его вероятность либо 0, либо 1. \ldots  В результате она равна 1.
\end{myex}


\subsection{Определение мартингала}

\begin{mydef}
Пусть $(\Omega,\F,P)$ - вероятностное пространство. Последовательность \s-алгебр $\{\F_{t}\}$ называется \indef{фильтрацией}, если $\F_{n}\subset \F_{n+1}$ и $\F_{n}\subset \F$ для всех $n$.
\end{mydef}

Говоря простым языком, $\F_{n}$ - это список событий, которые рациональный наблюдатель способен различить в момент времени $n$. С течением времени наблюдатель накапливает информацию (ничего не забывает), поэтому этот список становится все больше и больше.

\begin{mydef}
Процесс $X_{n}$ называется адаптированным к фильтрации $\F_{n}$ если для каждого $n$ случайная величина $X_{n}$ является $\F_{n}$-измеримой.
\end{mydef}

Другими словами, в любой момент времени $n$, информации, содержащейся в \s-алгебре $\F_{n}$ достаточно, чтобы сказать, чему равна случайная величина $X_{n}$. С каждым процессом всегда связана «естественная» фильтрация, а именно: $\F_{1}:=\s(X_{1})$, $\F_{2}:=\s(X_{1},X_{2})$, $\F_{3}:=\s(X_{1},X_{2},X_{3})$ и т.д.


\begin{mydef}
Случайный процесс $X_{n}$ называется мартингалом по отношению к фильтрации $\{\F_{n}\}$, если:
\begin{itemize}
\item[M1.] Для всех $n$ математическое ожидание $\E(X_{n})$ конечно.
\item[M2.] Процесс $X_{n}$ адаптирован к фильтрации $\F_{n}$.
\item[M3.] $\E(X_{n+1}|\F_{n})=X_{n}$ a.s.
\end{itemize}
\end{mydef}

Самое существенное условие M3 говорит: наилучший прогноз будущего значения мартингала - это его текущее значение. Поэтому бывает удобно представлять мартингал как благосостояние азартного игрока, играющего в «справедливую» игру в казино.

Иногда дают определение мартингала без явного упоминания фильтрации:
\begin{mydef}
Случайный процесс $X_{n}$ называется мартингалом, если:
\begin{itemize}
\item[M1.] Для всех $n$ математическое ожидание $\E(X_{n})$ конечно.
\item[M3'.] $\E(X_{n+1}|X_{n},X_{n-1},\ldots ,X_{1})=X_{n}$ a.s.
\end{itemize}
\end{mydef}

Это определение равносильно первому, если в качестве фильтрации взять естественную.


Примеры.

\begin{myex}. Случайное блуждание - мартингал относительно естественной фильтрации:
\begin{multline}
\E(X_{n+1}|\F_{n})=\E(X_{n}+I_{n+1}|\F_{n})=X_{n}+\E(I_{n+1}|\F_{n})=X_{n}+\E(I_{n})=X_{n},
\end{multline}
мы воспользовались тем, что $\F_{n}=\s(X_{1},X_{2},\ldots ,X_{n})=\s(I_{1},I_{2},\ldots ,I_{n})$. Поэтому $I_{n+1}$ не зависит от $\F_{n}$, а $X_{n}$ измерима относительно $\F_{n}$.
\end{myex}

Можно обобщить идею случайного блуждания. Не обязательно прибавлять плюс или минус единицу равновероятно. Главное, чтобы добавка имела нулевое условное ожидание, $\E(X_{n+1}-X_{n}|\F_{n})=0$. Например, если $I_{n}$ - независимые случайные величины, и $\E(I_{n})=0$, то $X_{n}=\sum_{i=1}^{n}I_{i}$ - мартингал.


\begin{myex}. Мультипликативный мартингал. $X_{1}=1$, случайные величины $I_{n}$ - независимы и $\E(I_{n})=1$. Рассмотрим $X_{n}=\prod_{i=1}^{n} I_{i}$. Он является мартингалом относительно естественной фильтрации:
\begin{multline}
\E(X_{n+1}|\F_{n})=\E(X_{n}\cdot I_{n+1}|\F_{n})=X_{n}\cdot \E(I_{n+1}|\F_{n})=X_{n}\E(I_{n})=X_{n},
\end{multline}
\end{myex}

Хозяйке на заметку! Если у вас в холодильнике есть случайный процесс, не являющийся мартингалом, а до прихода гостей осталось несколько минут, то из него можно сварить превосходный мартингал!

Может эти сюжету включить после? Т.к. не совсем понятно, зачем варить мартингал?


Если в холодильнике завалялась последовательность iid\ldots

Пусть $I_{i}$ - независимые одинаково распределенные случайные величины с $\E(I_{i})\neq 0$.

\begin{itemize}
\item[Рецепт 1.] Отрежем лишнее! Определим $X_{n}:=\sum_{i=1}^{n} I_{i}-n\E(I_{i})$.
\item[Рецепт 2.] Создание «мультипликативного мартингала». Найдем такое число $a>0$, что $\E(a^{I_{i}})=1$. Определим $X_{n}:=a^{\sum_{i=1}^{n}I_{i}}$.
\end{itemize}

Если в холодильнике только марковская цепь\ldots  [Нужна ли глава про марковские цепи?]

Рецепт 3. Если $X_{n}$ - цепь маркова, то можно поискать такую функцию $f$, что $M_{n}=f(X_{n})$ - мартингал.

\begin{myex}
Пусть $X_{1}=1$, а далее в каждый момент времени мы делаем шаг либо вправо, либо влево. Вероятности зависят от $n$ и равны $p_{n\to n+1}=\frac{n+1}{2n}$ и $p_{n\to n-1}=\frac{n-1}{2n}$. Найдите такое преоборазование $f$, что $f(X_{n})$ - мартингал.

Решение. Если $f(X_{n})$ - мартингал, то и $af(X_{n})+b$ - тоже мартингал

Т.к. $f(X_{n})$ - это мартингал, то получаем следующее рекуррентное соотношение:
\begin{equation}
f(n)=p_{n\to n-1} f(n-1)+p_{n\to n+1} f(n+1)
\end{equation}

В нашем случае:
\begin{equation}
f(n)=\frac{n-1}{2n}f(n-1)+\frac{n+1}{2n} f(n+1)
\end{equation}

Как решить такое разностное уравнение? Можно домножить на $n$ и сделать замену $g(n)=nf(n)$. После этого получим линейное уравнение и находим, что $g(n)=c_{1}+c_{2}n$. Т.е. $f(n)=\frac{c_{1}}{n}+c_{2}$.

Мы вольны выбрать любое решение, поэтому выбираем самое простое, $f(n)=\frac{1}{n}$. Т.е. $M_{n}=1/X_{n}$ - это мартингал. Конечно, $M_{n}:=0$ тоже мартингал, но он не будет полезен при нахождении вероятностей связанных с процессом $X_{n}$.
\end{myex}







Высший пилотаж! В холодильнике всего одна случайная величина!!!

\begin{myex}
Рецепт 4. Мартингал Леви. Берем произвольную случайную величину $X$ с $\E(X)<\infty$ и произвольную фильтрацию $\F_{n}$. И строим последовательность $X_{n}$ по принципу $X_{n}:=\E(X|\F_{n})$.
\end{myex}

Неожиданно, но многие мартингалы устроены по принципу мартингала Леви. Даже если \ldots









У мартингалов есть два очень хороших свойства:
\begin{itemize}
\item Во-первых, многие преобразования оставляют мартингал мартингалом.
\item Во-вторых, многие мартингалы сходятся. (\ldots ) сюда про Леви
\end{itemize}
Поэтому очень часто при изучении случайных процессов не являющихся мартингалами полезно увидеть мартингал.



\subsection{Момент остановки}
% момент остановки обозначаем буквой тау! (так у Steele)

\begin{mydef} Случайная величина $\tau$, принимающая значения из
множества $\{1,2,\ldots \}\cup \{+\infty\}$ называется моментом
остановки, если $\{\tau=n\} \in \mathcal{F}_{n}$ для любого $n$.
\end{mydef}

Другими словами, вывод о том, что надо остановиться в момент
времени $n$ можно сделать в момент времени $n$. Возможно, что вывод может быть сделан и раньше (так как вполне возможно, что событие $\{\tau=n\}$ содержится не только в \s-алгебре $\F_{n}$, но и в более ранней).

\begin{myex} Момент времени, когда индекс Доу-Джонса,
достигает своего ежегодного максимума, не является моментом остановки. Этот момент времени не обнаруживается сразу, чтобы понять, что он был в момент времени $n$, нужно ждать конца года. Мы не можем использовать стратегию типа «когда индекс достигнет своего годового максимума я сделаю то-то и то-то». Хотя,
безусловно, этот момент времени - случайная величина.
\end{myex}

\begin{myex} Момент первого касания (first hitting time). Момент $\tau$ - это тот день, когда индекс Доу-Джонса впервые превысит $1000$, $\tau=\min\{n|X_{n} \ge 1000\}$. Если траектория такова, что индекс никогда не превышает 1000, то $\tau=+\infty$.
\end{myex}


Дадим эквивалентное определение:

Упражнение. Убедитесь, что определение не изменится, если
$\{\tau=n\}$ заменить на $\{\tau \le n\}$ или на $\{\tau > n\}$ \par

Упражнение. Если $\tau$ - момент остановки, то множества $\{\tau<n\}$,
$\{\tau\le n\}$, $\{\tau=n\}$, $\{\tau\ge n\}$ и $\{\tau>n\}$ лежат в
$\mathcal{F}_{n}$. \par



Упражнение. \par
Верно ли, что $\tau=a$ - момент остановки? \par

Пусть $\tau_1$ и $\tau_2$ - моменты остановки, верно ли что $\tau_1\wedge \tau_2$,
$\tau_1\vee \tau_2$, $\tau_1+a$ и $\tau_1+\tau_2$ - моменты остановки? \par

\subsubsection{Информация к моменту остановки.}

Каждому моменту остановки $\tau$ можно сопоставить $\sigma$-алгебру,
отражающую всю информацию, известную к моменту времени $\tau$. \par
\begin{mydef}
Пусть $\tau$ - момент остановки.
\begin{equation}
\mathcal{F}_{\tau}:=\{A \in \mathcal{F}|A\cap \{\tau=n \} \in
\mathcal{F}_{n},\forall n\}
\end{equation}
\end{mydef}



\begin{mydef}
Если $\tau$ - время первой аварии на недавно построенном
шоссе, то событие $A=\{$за день до аварии был туман$\}$ лежит в
$\mathcal{F}_{\tau}$. Это событие может не содержаться ни в одной
$\mathcal{F}_{n}$. \par
Событие $B=\{$на следующий день после аварии был туман$\}$ в
$\mathcal{F}_{\tau}$ может не содержаться.
\end{mydef}




В $\mathcal{F}_{\tau}$ входят те события, про которые в момент
времени $\tau$ точно можно будет
сказать, произошли они или нет.\par
Если возможно несколько сценариев развития события, при одном из
которых мы в момент времен $N$ будем знать, произошло ли $A$ или
нет, а при другом - не будем знать, то $A$ в $\mathcal{F}_{\tau}$ не
входит. \par
$\mathcal{F}_{\tau}$ - это не случайный объект а 'нормальная'
$\sigma$-алгебра. \par
Полезно представлять себе $\mathcal{F}_{n}$ как газету, выходящую
в день $n$, а $\sigma$-алгебру $\mathcal{F}_{\tau}$ как спецвыпуск
газеты, посвященный произошедшей аварии (или другому наступившему
моменту остановки). \par

Упражнение. \par
Определение не изменится, если $\tau=n$ заменить на $\tau\le n$. \par

Упражнение. \par
Если $\tau$ - момент остановки, то $\mathcal{F}_{\tau}$ - действительно
$\sigma$-алгебра и $\tau\in \mathcal{F}_{\tau}$. \par

Упражнение. \par
$N\equiv n \Rightarrow \mathcal{F}_{N}=\mathcal{F}_{n}$ и $N\equiv +\infty \Rightarrow \mathcal{F}_{N}=\mathcal{F}$ \par

Упражнение. \par
Если $\tau<+\infty$ - момент остановки и $Y_{n}\in\mathcal{F}_{n}$,
то $Y_{\tau}\in\mathcal{F}_{\tau}$. \par
В частности, из этого упражнения следует, что
$\sum_{i=1}^{\tau}Y_{i}$ и $\max_{n\le \tau}\sum_{i=1}^{n}Y_{i}$ являются
$\mathcal{F}_{\tau}$-измеримыми. \par

Упражнение. \par
Если $M$ и $N$ - моменты остановки, то
$\mathcal{F}_{M}\cap\mathcal{F}_{N}=\mathcal{F}_{M\wedge N}$ \par
"Доказательство": Вынесем $\mathcal{F}$ за скобки и заострим $\cap$ :) \par

Упражнение. Если $N$ - момент остановки, то $\mathcal{F}_{N\wedge
n} \subseteq \mathcal{F}_{n}$ \par

Упражнение. \par
Пусть $M\le N$ - моменты остановки.
Как связаны между собой $\sigma$-алгебры $\mathcal{F}_{M}$ и $\mathcal{F}_{N}$? \par

Упражнение. \par
Пусть $T$ - момент остановки, $A\in\mathcal{F}_{T}$ и $m\le n$.
Тогда $A\cap\{T=m\}\in\mathcal{F}_{T\wedge n}$ \par

Упражнение. \par
Пусть $T_{1}$, $T_{2}$, $T_{3}$, \ldots  - моменты остановки и
существует $T=\lim_{n\rightarrow +\infty}T_{n}$. Тогда $T$ - момент
остановки. \par

Упражнение. \par
Пусть $T_{1}\ge T_{2}\ge T_{3}\ge \ldots $ - последовательность
моментов остановки с пределом $T$. Докажите, что
$\mathcal{F}_{T}=\cap_{n}\mathcal{F}_{T_{n}}$. \par
Пусть $T_{1}\le T_{2}\le T_{3}\le \ldots $ - последовательность
моментов остановки с конечным пределом $T$. Докажите, что
$\mathcal{F}_{T}=\sigma(\cup_{n}\mathcal{F}_{T_{n}})$. \par
Приведите пример к предыдущему утверждению, доказывающий
необходимость конечности $T$. \par
Подсказка: \par
$$
\Omega=\bigcup_{n}\bigcup_{L=1}^{\infty}\bigcap_{l=L}^{\infty}\left(T_{l}=T=n\right)
$$



\subsection{Остановленный мартингал}



% про теорему о моменте остановки
% сначала в дискретном времени, потом в непрерывном

% идеология: лучше сделать лишний повтор, ибо: 1 - можно рассказать несколько раз, не опасаясь, что кто-нибудь поймет :), 2 - появляется большая независимость глав.

% аудитория: студенты-нематематики, хотя и студенты-математики могут найти что-нибудь новое для себя


% \section{Теорема Дуба}

На стиль изложения во многом повлияли источники \cite{stirzaker:prp}, \cite{chang:sp}, \cite{ross:scp}

Пусть $X_{t}$ - наше благосостояние в справедливой игре в момент времени $t$ или мартингал. Наша стратегия заключается в том, чтобы в нужный момент завершить игру, скажем, после крупного выигрыша. Другими словами, наша стратегия определяется моментом остановки $T$. Этот момент остановки - случайная величина, так как может зависить от хода игры. Случайной величиной является также и $X_{T}$ - выигрыш на момент выхода из игры. Вопрос в том, чему равен средний выигрыш на момент прекращения игры, $\E(X_{T})$?

Ответ дает теорема Дуба:
Если не ждать «слишком» долго, то каким бы хитрым не был момент остановки ожидаемый выигрыш будет равен начальной сумме, $\E(X_{T})=\E(X_{1})$.

Сразу приведем пример «слишком» долгого ожидания: ждать до выигрыша в один рубль в классическом случайном блуждании. Условие  $\E(X_{T})=\E(X_{1})$ здесь нарушено: выигрыш на момент выхода из игры равен одному рублю (по построению), а стартовая сумма равна нулю. Почему это слишком долгое ожидание? Потому, что в этом случае можно доказать, что $\E(T)=+\infty$.

Заметим, что для того, чтобы случайная величина $ X_{T} $ была определена (хотя бы почти наверное) необходимо, чтобы $ \P(T<\infty)=1 $.

Точный смысл понятия «слишком» долго можно увидеть в теореме:

Если $X_{t}$ - мартингал, $T$ - момент остановки, $ \P(T<\infty)=1 $, и выполнено хотя бы одно из пяти условий:
\begin{itemize}
\item [TD1.] Момент $T$ ограничен, то есть существует число $M$, такое что $T<M$.

\item [TD2.] Процесс $X_{t\wedge T}$ ограничен, то есть существует число $M$, такое что для любого $t$ верно неравенство $|X_{t\wedge T}|<M$.

\item [TD3.] $\E(T)<+\infty$ и существует число $M$, такое что для любого $t$ верно неравенство $\E(|X_{t+1}-X_{t}||\mathcal{F}_{n})<M$.

\item [TD4.] $\E(|X_{T}|)<\infty$ и $lim_{t\to\infty}\E(X_{t}1_{T>t})=0$.

\item [TD5.] Мартингал $X_{t}$ является равномерно интегрируемым.

\end{itemize}


То: $\E(X_{T})=\E(X_{1})$.

В большинстве случаев первых трех критериев достаточно для практического применения.
Четвертый критерий является следствием любого из первых трех (?).

В пятом критерии используется определение равномерной интегрируемости\ldots
Набор случайных величин является равномерно интегрируемым, если\ldots


Из этих критериев все кроме третьего (может есть какой-то «предельный» аналог и третьего? - я не знаю) работают в непрерывном времени.

Из теоремы Дуба легко вывести тождество Вольда. Wald's identity.

Если складывать случайное количество случайных величин (опять же, не «слишком» много), то среднее значение суммы равно произведению среднего размера слагаемых на среднее количество слагаемых. Это кажется очевидным, но на самом деле не все так просто, так теорема допускает, что количество слагаемых может зависить от размера слагаемых.

Если $X_{i}$ - независимые одинаково распределенные случайные величины и $T$ - случайная величина принимающая целые неотрицательные значения и $\E(T)<\infty$, то $\E(\sum_{i=1}^{T}X_{i})=\E(X_{i})\E(T)$.

Доказательство:

Случаный процесс $M_{t}=\sum_{i=1}^{t}X_{i}-t\cdot \E(X_{i})$ - мартингал. Применяя к нему теорему Дуба получаем, что $\E(M_{T})=\E(M_{1})$. Здесь $\E(M_{1})=0$, $M_{T}=\sum_{i=1}^{T}X_{i}-T\cdot \E(X_{i}$, поэтому $\E(\sum_{i=1}^{T}X_{i})=\E(X_{i})\E(T)$.




%\section{Примеры}

Между примерами и задачами нет существенного различия. Если легко, то можно взять условие примера и попробовать его решить как задачу. А если тяжело, то можно посмотреть решение задачи. Пожалуй, тексты примеров в каком-то смысле «классические». Иногда используемые для решения мартингалы настолько изящны, что вспоминаются субтитры при показе сложных трюков по телевизору: «Трюки выполнены профессиональными каскадерами. Не пробуйте повторить их самостоятельно». Только здесь нужно пробовать!

% включить доказательство без теоремы Дуба


Задача. Симметричное случайное блуждание.

Улитка начинает свой путь в точке 0 и за каждую минуту равновероятно смещается влево или вправо на один сантиметр\footnote{Скорость виноградной улитки около 4 см в минуту, но у нас улитка попалась ленивая.}. Справа от улитки на расстоянии $a$ находится виноградное дерево, слева на расстоянии $b$ - шелковица.

Какова вероятность того, что улитка доползет до виноградного дерева раньше? Сколько в среднем времени ей потребуется чтобы доползти до любого из деревьев?

Решение с мартингалами: $X_{t}$ - координата улитки в момент времени $T$ - мартингал. Пусть $T$ - момент достижения одной из границ ($a$ или $-b$), тогда $|X_{t\wedge T}|\leq \max\{a,b\}$. Момент времени $T$ можно смажорировать геометрической случайной величиной. Разобьем время на интервалы по $(a+b)$ шагов. Будем засчитывать выход за пределы множества $(-b;a)$ только на границах этих интервалов. Очевидно, что требуемое для выхода время от этого только возрастет.

За каждый интервал вероятность выхода случайного блуждания за пределы множества $(-b;a)$ выше чем $(1/2)^{a+b}$ (это вероятность того, что случайное блуждание сделает $(a+b)$ шагов вправо). Значит требуемое для выхода количество временных интервалов можно ограничить сверху случайной величиной $M$ с геометрическим распределением и вероятностью успеха равной $p=(1/2)^{a+b}$. Получаем, что $\P(T=\infty)\leq \P(M=\infty)=0$ и $\E(T)\leq (a+b) \E(M)=(a+b) 2^{a+b}$.

Применяя пункт (ii) теоремы Дуба получаем, что $\E(X_{T})=\E(X_{1})$. По условию $\E(X_{1})=0$. Величина $X_{T}$ может принимать только два значения $a$ или $-b$. Пусть значение $a$ принимается с вероятностью $p$. Тогда $pa+(1-p)(-b)=0$ и $p=\frac{b}{a+b}$.

Заметим также, что $M_{t}=X^{2}_{t}-t$ - также мартингал: $\E(M_{t+1}-M_{t}|\mathcal{F}_{t})=\E(2X_{t}\Delta X_{t+1}+(\Delta X_{t+1})^{2}-1|\mathcal{F}_{t})=2X_{t}\E(\Delta X_{t+1}|\mathcal{F}_{t})+\E((\Delta X_{t+1})^{2})-1=0+1-1=0$.

Применяя ??? пункт (iii) теоремы Дуба получаем, что $\E(M_{T})=\E(M_{1})$. При этом $\E(M_{1})=0$, а $M_{T}=X_{T}^{2}-T$, значит $\E(X_{T}^{2})=\E(T)$. Величина $X_{T}^{2}$ принимает только два значения: $a^{2}$ и $b^{2}$, значит $\E(T)=a^{2}\frac{b}{a+b}+b^{a}\frac{a}{a+b}=ab$.

Задача. Несимметричное случайное блуждание

Улитка начинает свой путь в точке 0 и за каждую минуту смещается влево или вправо на один сантиметр. Однако влево идти улитке не очень хочется, поэтому вправо она идет с вероятностью $p>1/2$, влево - с вероятностью $(1-p)$. Справа от улитки на расстоянии $a$ находится виноградное дерево, слева на расстоянии $b$ - шелковица.

Какова вероятность того, что улитка доползет до виноградного дерева раньше? Сколько в среднем времени ей потребуется чтобы доползти до любого из деревьев?

Решение с мартингалами: $X_{t}$ - координата улитки в момент времени $T$ - не мартингал, т.к. в улитка склонна смещаться вправо.

Как сварить из немартингала мартингал? Один из стандартных приемов следующий: вместо процесса $X_{t}$ рассмотреть процесс $M_{t}=u^{X_{t}}$, где число $u$ подбирается так, чтобы $M_{t}$ стал мартингалом. Из нескольких возможных $u$ выбирают $u\neq 1$, т.к при $u=1$ процесс $M_{t}$ всегда будет равен 1.

Ищем $u$ в нашем случае. Требуем, чтобы $M_{t}$ был мартингалом: $\E(M_{t+1}|\mathcal{F}_{t})=M_{t}$. Это условие упрощается до $\E(u^{\Delta{X}_{t+1}})=1$ или $p\cdot u^{1}+(1-p)\cdot u^{-1}=1$.
Квадратное уравнение имеет два корня, $u=1$ и $u=\frac{1-p}{p}$, выбираем второй.

Как и в случае симметричного случайного блуждания улитки $\P(T=\infty)=0$, $\E(T)<\infty$ так как время $T$ снова мажорируется геометрической случайной величиной. Также и процесс $M_{t\wedge T}$ ограничен сверху.

Применяя пункт (ii) теоремы Дуба получаем, что $\E(M_{T})=\E(M_{1})$. Величина $M_{T}$ принимает всего два значения: $u^{a}$ и $u^{-b}$, а $\E(M_{1})=1$. Пусть $p$ - вероятность доползти сначала до точки $a$ (виноградного дерева). Из уравнения $pu^{a}+(1-p)u^{-b}=1$ находим $p=\frac{\ldots }{\ldots }$.

Чтобы найти $\E(T)$ можно использовать мартингал $Y_{t}=X_{t}-t\cdot \E(\Delta X_{t})$ или, что в принципе то же самое, тождество Вольда. По тождеству Вольда среднее количество слагаемых равно среднему значению суммы делить на средний размер слагаемого: $\E(T)=\frac{\E(Y_{T})}{\E(\Delta X_{t})}=\ldots $


Задача. ABRACADABRA \cite{ross:scp}\cite{williams:pwm}
% Ross, Second course, Williams, probability with martingales

Если одна мартышка печатает наугад буквы на клавиатуре, то она рано или поздно с единичной вероятностью напечатает роман Льва Толстого «Война и мир». Мы поставим вопрос по-другому: сколько нажатий на клавиши в среднем потребуется чтобы напечатать слово «абракадабра»? Какова дисперсия требуемого количества нажатий?

Решение через мартингалы.  Организуем казино! Перед каждым нажатием в казино приходит
новый игрок с начальным капиталом в 1 рубль. Каждый входящий игрок
действует по одной и той же схеме: ставит все имеющиеся деньги на
очередную букву слова АБРАКАДАБРА (войдя в казино игрок ставит на А, потом на Б, потом на Р и т.д. Если слово кончилось, то игрок покидает казино с выигрышем). Если обезьяна напечатала нужную букву, то игрок получает свою ставку, увеличенную в 33 раза, если нет - то игрок покидает казино без денег.

Пусть $X_{t}$ - суммарное благосостояние всех игроков, начавших игру до нажатия номер $t$. Величина $X_{t}$ естественно раскладывается на благосостояния отдельных игроков пришедших в казино $X_{t}=Y_{1t}+\ldots +Y_{tt}$. Здесь $Y_{it}$ - это благосостояние $i$-го игрока после нажатия номер $t$. Заметим, что для каждого игрока $Y_{it}$ - это мартингал, т.к. игра справедливая - на каждом шаге игрок либо теряет деньги, либо с вероятностью $1/33$ увеличивает свой выигрыш в 33 раза. Так как игроки начинают с одного рубля, то $\E(Y_{it})=1$. Чистый выигрыш игроков к моменту времени $t$, $M_{t}=X_{t}-t$ оказывается мартингалом: $\E(M_{t+1}-M_{t}|\mathcal{F}_{t})=\E(Y_{1,t+1}-Y_{1,t}|\mathcal{F}_{t})+\ldots +\E(Y_{t,t+1}-Y_{t,t}|\mathcal{F}_{t})+\E(Y_{t+1,t+1}-1|\mathcal{F}_{t})=0$.

Заметим, что когда слово «абракадабра» напечатано впервые, все игроки кроме трех проиграли по одному рублю. Угадавший «абракадабра» имеет $33^{11}$, угадавший «абра» имеет $33^{4}$ и угадавший «а» имеет $33$ рубля. Значит $M_{T}=33^{11}+33^{4}+33-T$. Также получаем, что $M_{t}1_{T>t}\leq (33^{11}+33^{4}+33)1_{T>t}$.

Время $T$ можно смажорировать с помощью геометрической случайной величины. Можно давать обезьяне чистый лист после каждый 11 нажатий и засчитывать «абракадабру», только если слово напечатано на отдельном листе. Очевидно, что ожидаемое время при этом возрастет. Количество листов $L$ будет иметь геометрическое распределение с $p=\frac{1}{33^{11}}$ и $\E(L)=33^{11}$. Значит $T<11L$ и $\E(T)<\E(11\cdot L)=11\cdot 33^{11}$.

Для геометрического распределения $\P(L>t)$ стремится к нулю при $t\to\infty$. Значит $\E(M_{t}1_{T>t}\leq (33^{11}+33^{4}+33)\E(1_{T>t})\leq (33^{11}+33^{4}+33) \P(L<t/11)$ стремится к нулю.

Применяя пункт (iv) теоремы Дуба получаем, что $\E(M_{T})=\E(M_{1})$. При этом $\E(M_{T}=(33^{11}+33^{4}+33)-\E(T)$, а $\E(M_{1})=0$, значит $\E(T)=33^{11}+33^{4}+33$.

Про дисперсию. Теперь игроки приходят в наше казино с возрастающими суммами денег: первый с одним рублем, второй - с двумя и т.д. Снова рассмотрим $X_{t}$, суммарное благосостояние игроков вступивших в игру к моменту времени $t$ и чистый выигрыш этих игроков, $M_{t}=X_{t}-(1+2+\ldots +t)=X_{t}-\frac{t(t+1)}{2}$.

При данном изменении выигравших будет также трое и на момент появляения «абракадабры» общий чистый выигрыш составит $M_{T}=(T-10)\cdot 33^{11}+(T-3)\cdot 33^{4}+T\cdot 33-\frac{T(T+1)}{2}$.

Как и раньше $\E(T)<\infty$ и $\E(M_{t}1_{T>t})\to 0$ \ldots

Применяя пункт (iv) теоремы Дуба получаем, что $\E(M_{T})=\E(M_{1})$. Значит $\E(M_{T})=0$. Из этого уравнения выражается $\E(T^{2})$, а затем и по формуле $Var(T)=\E(T^{2})-\E(T)^{2}$ находим дисперсию $Var(T)=(33^{11}+33^{4}+33)^{2}-(11\cdot 33^{11}+4\cdot 33^{4}+ 33)$.


Задача. «Следующая карта - дама» \cite{morters:m}, \cite{winkler:gpdp}

Перед гадалкой колода из 36 карт, хорошо перемешанная. Гадалка
должна предсказать появление дамы. Гадалка открывает
одну за другой карты из колоды и в любой момент может остановиться
и сказать «Следующая карта будет дамой». Если это окажется правдой, то гадалка выиграла.

Какую вероятность выигрыша дает следующая стратегия: дождаться появления первой дамы и после этого рискнуть и заявить, что следующая карта будет дамой? Какова оптимальная стратегия? Каковы при шансы выиграть при оптимальной стратегии?

Решение через мартингалы. Рассмотрим процесс $X_{t}$ - долю дам в еще неоткрытой части колоды после $t$ открытых карт. После $t$ открытых карт в колоде остается $(36-t)$ карт, из которых $(36-t)X_{t}$ дам. С вероятностью $X_{t}$ (доля дам совпадает с вероятностью открыть даму) количество дам уменьшится на одну.

Считаем $\E(X_{t+1}|\mathcal{F}_{t})=\E(X_{t+1}|X_{t})=\frac{(36-t)X_{t}+X_{t}(-1)}{36-t-1}=X_{t}$.

Значит, $X_{t}$ - мартингал. Момент остановки $T$ в любом случае ограничен 36 картами, следовательно, требования пунтка (i) теоремы Дуба выполнены и $\E(X_{T})=\E(X_{0})=\frac{4}{36}$ для любой стратегии.

Решение без мартингалов. Шансы гадалки не меняются, если она будет угадывать последнюю карту, а не следующую: информации о последней карте ровно столько, сколько о следующей. А шансы того, что последняя карта будет дамой равны $\frac{4}{36}$.
Значит все стратегии оптимальны и дают выигрыш в $4/36$

Задача. «И в воздух чепчики бросали\ldots » % Ross, Second Course in Probability

Приезжающих из армии или от двора встречают $n$ женщин. Они
одновременно подбрасывают вверх $n$ чепчиков. Ловят чепчики
наугад, каждая женщина ловит один чепчик.
Женщины, поймавшие свой чепчик уходят. А женщины,
поймавшие чужой чепчик, снова подбрасывают его вверх.
Подбрасывание чепчиков продолжается до тех пор, пока каждая не
поймает свой чепчик.

Найдите:

а) среднее количество женщин, поймавших свой чепчик при одном подбрасывании

б) среднее количество подбрасываний

Решение с мартингалами. Пусть $N_{1}$ - количество женщин поймавших чепчики при первом подбрасывании. Величина $N$ легко раскладывается в сумму индикаторов: $N_{1}=X_{1}+\ldots +X_{n}$, где $X_{i}$ - принимает значение 0 или 1 в зависимости от того, поймала ли $i$-ая женщина свой чепчик. Находим $\E(X_{i})=\P(X_{i}=1)=1/n$ и $\E(N_{1})=n\cdot \frac{1}{n}=1$. Аналогично и для остальных раундов, где участвует меньшее количество женщин.

Значит в каждом раунде в среднем одна женщина ловит свой чепчик. Пусть $Y_{t}=N_{1}+\ldots +N_{t}$ - суммарное количество женщин поймавших свой чепчик после раунда $t$. Получаем, что $\E(Y_{t})=t$. Случайный процесс $M_{t}=Y_{t}-t$ - это мартингал, так как $\E(M_{t+1}|\mathcal{F}_{t})=\E(M_{t+1}|M_{t})=\E(M_{t}+N_{t+1}-1|M_{t})=M_{t}$. Разность $M_{t+1}-M_{t}=N_{t+1}-1$ ограничена количеством женщин $n$.

Смажорируем $T$, чтобы увидеть, что $\E(T)<\infty$. Вероятность того, что конкретная женщина поймает свой чепчик равна единице делить на количество женщин, участвующих в раунде, а следовательно не меньше $1/n$. Если вместо подбрасывания чепчиков в каждом раунде одна (любая) женщина будет уходить с вероятностью $1/n$, а с вероятностью $1-1/n$ не будет уходить никто, то ожидаемое количество раундов возрастет (занижена вероятность ухода, возможность ухода нескольких женщин за один раунд исключена). Количество раундов для ухода одной женщины в этом случае будет иметь геометрическое распределение со средним значением $n$ раундов, а ожидаемое общее количество раундов равно $n^{2}$. Следовательно, $\E(T)<n^{2}$.

Применяя пункт (iii) теоремы Дуба получаем, что $\E(M_{T})=\E(M_{1})$. Так как $M_{T}=Y_{T}-T=n-T$ и $\E(M_{1})=\E(N_{1}-1)=0$, получаем, что $\E(T)=n$.

Ключи и сейфы \cite{aops:keys} % aops:keys

Ballot problem \cite{ross:scp} % Ross, Second




Задача. РРО против ОРО\cite{li:ma}. % Li, Martingale Approach

Правильную монетку подбрасывают до появления последовательности РРО или ОРО. Сколько подбрасываний в среднем нужно? Какова вероятность того, что подбрасывания закончатся последовательностью РРО?

Решение с мартингалами. ???

Решение без мартингалов. ???



Задача. «Вампиры-гладиаторы» \cite{winkler:gpdp} % Winkler, Games people don't play

Две команды вампиров-гладиаторов борются за победу в турнире. В вашей команде 100 вампиров с силами от 1,2,\ldots , 100. В команде противника 59 вампиров с силами 72,73,\ldots , 130. Турнир состоит из последовательных раундов в каждом из которых участвует по одному гладиатору с каждой стороны. Если встретились гладиаторы с силами $a$ и $b$, то первый побеждает с вероятностью $\frac{a}{a+b}$, а второй - с вероятностью $\frac{b}{a+b}$. Победитель добавляет к свой силе силу побежденного (получает силу $a+b$), а побежденный выбывает из турнира (получает силу $0$). Турнир продолжается до полного выбывания одной из команд.

Вы знаете, что команда противника будет выставлять гладиаторов по следующему принципу: на арену всегда выходит самый слабый из команды.

Какова ваша оптимальная стратегия? Какова вероятность выигрыша при этой стратегии?

Решение с мартингалами. Пусть $X_{t}$ - суммарная сила гладиаторов нашей команды после $t$ боев. Процесс $X_{t}$ - мартингал: $\E(X_{t+1}-X_{t}|\mathcal{F}_{t})=\frac{a}{a+b}b+\frac{b}{a+b}(-a)=0$.

Момент окончания турнира $T$ ограничен, т.к. за каждый раунд выбывает ровно один гладиатор, то есть $T<100+59$.

Применяя пункт (i) теоремы Дуба получаем, что $\E(X_{T})=\E(X_{0})$. Начальная суммарная сила нашей команды, $X_{0}=50\cdot 101$. В конце турнира суммарная сила $X_{T}$ может принимать два значения: либо 0, если мы проиграли, либо $50\cdot 101+59\cdot 101$. Если $p$ - вероятность нашей победы, то $(1-p)\cdot 0+p\cdot (109\cdot 101)=50\cdot 101$. Значит $p=\frac{50}{109}$. Причем результат не зависит от используемой стратегии, т.к. она нигде не использовалась при подсчете!




% Задача. «Гладиаторы» - а может у нее нет мартингального решения?

% Задача. Какую долю от имеющейся ставить на цвет следующей карты?
% есть ли мартингальное решение




% Задача о втором тузе. \cite{morters:m} - совмещена с гадалкой
% Second heart problem -  Morters, Martingales, p. 31

% На столе хорошо перемешанная колода из 36 карт. Карты открывают одну за одной до появления первого туза. Какова вероятность того, что следующая карта будет тузом?

% Решение через мартингалы. Рассмотрим процесс $X_{t}$ - долю тузов в еще неоткрытой % части колоды после $t$ открытых карт. После $t$ открытых карт в колоде остается % $(36-t)$ карт, из которых $(36-t)X_{t}$ тузов. С вероятностью $X_{t}$ (доля тузов % совпадает с вероятностью открыть туза) количество тузов уменьшится на один.

% Считаем %$\E(X_{t+1}|\mathcal{F}_{t})=\E(X_{t+1}|X_{t})=\frac{(36-t)X_{t}+X_{t}(-1)}{36-t-1}=X_{t}% $ .

% Значит, $X_{t}$ - мартингал. Оптимальный момент остановки $T$ в любом случае %ограничен 36 картами, следовательно, требования пунтка (i) теоремы Дуба выполнены и $ %\E(X_{T})=\E(X_{0})=\frac{4}{36}$.

% Решение без мартингалов. Шансы открыть туза не меняются, если открывать последнюю  карту, а не следующую: информации о последней карте ровно столько, сколько о следующей. % А шансы того, что последняя карта будет тузом равны $\frac{4}{36}$.






%\section{Задачи}

Ряд задач взят из \cite{stirzaker:prp}, \cite{stirzaker:otep}, \cite{zastawniak:bsp}, \cite{blom:pspt}


Задача.

%Усталость улитки.
%Усталость улитки в момент времени $t$ определяется как $U_{t}=t\cdot S_{t}$ (чем %дальше улитка
% эх плохо - разный знак у S_{t} - как бы это обозвать?

Пусть $X_{t}$ - симметричное случайное блуждание.

Найдите $\E(TS_{T})$,

Задача. \cite{wilmott:chap} % wilmott:chap

Бабушка изготовила кисель. В банке киселя плавают 10 вишенок. За один день Вовочка выпивает случайное количество киселя равномерно распределенное от нуля до всей банки. Вовочка пьет кисель прямо с вишенками, если они ему попадаются. Чтобы бабушка ничего не заметила каждый день Вовочка доливает в банку воды до полного объема.
Вовочка пьет до тех пор пока в банке не останется 5 вишенок. Пусть $T$ - количество дней, которые Вовочка будет пить кисель, а $X_{t}$ концентрация киселя в день $t$.

Докажите, что $\E(T)=-\E(\ln X_{T})$

Решение. Заметим, что $ X_{t+1}=X_{t}\cdot U_{t+1} $, где $ U_{t} $ --- доля невыпитого Вовочкой в день $ t $ равномерно распределена на $ [0;1] $. Применяем народную примету: если есть умножение, значит логарифм где-то рядом. Поигравшись получаем мартингал: $ M_{t}=\ln(X_{t})+t$. Применяем к нему теорему Дуба: $\E(\ln X_{T})+\E(T)=0$ .




Задача. Вариация на тему дней рождения.

Мы набираем людей по одному в группу до тех пор, пока в группе не будет хотя бы одного совпадающего дня рождения. Пусть $T$ количество людей, которое потребуется набрать. Найдите\footnote{величина $\E(T)$ является «некрасивой» в том смысле, что не целая и точное значение имеет громоздкую запись. Оказывается, что $\E(T)\approx 23$, но для в решении данной задачи это не используется} $\E(T^{2})-\E(T)$.

Решение через мартингалы. Каждый вступающий человек приходит в группу с количеством денег равным количеству людей уже вступивших в группу. Обяжем каждого вступающего человека сыграть с каждым уже вступившим в группу в такую лотерею: входящий ставит на кон 1 рубль, если их дни рождения совпадают, то входящий получает 365 рублей, если нет, то входящий теряет рубль (деньги платит и получает устроитель, существующие члены группы ничего не платят и не получают). Пусть $X_{t}$ - чистый выигрыш всех участников после вступления в группу $t$ человек. Поскольку каждая лотерея по отдельности справедлива, то $X_{t}$ - мартингал.

Момент остановки $T$ ограничен сверху, $T\leq 365$. Применяя пункт (i) теоремы Дуба получаем, что $\E(X_{T})=\E(X_{1})$. При этом $\E(X_{1})=0$, а $X_{T}=365-(1+2+\ldots +(T-1))=365-\frac{T(T-1)}{2}$. И $\E(T^{2}-T)=2\cdot 365$.

Задача. Улитка отдыхает (симметричное блуждание), \cite{blom:pspt}
% r-in-advance game, Blom, Problems and Spanshots from probability theory

Улитка начинает свой путь в точке 0 и за каждую минуту равновероятно смещается влево или вправо на один сантиметр или отдыхает никуда не перемещаясь. Влево (и вправо) улитка ползет с одинаковой вероятностью $p$, отдыхает - с вероятностью $(1-2p)$.

Справа от улитки на расстоянии $a$ находится виноградное дерево, слева на расстоянии $b$ - шелковица.

Какова вероятность того, что улитка доползет до виноградного дерева раньше? Сколько в среднем времени ей потребуется чтобы доползти до любого из деревьев?



Задача. Улитка отдыхает (несимметричное блуждание), \cite{blom:pspt}
% r-in-advance game, Blom, Problems and Spanshots from probability theory

Улитка начинает свой путь в точке 0 и за каждую минуту смещается влево или вправо на один сантиметр или отдыхает никуда не перемещаясь. Влево улитка ползет с вероятностью $p_{l}$, вправо - с вероятностью $p_{r}$, отдыхает - с вероятностью $(1-p_{l}-p_{r})$.

Справа от улитки на расстоянии $a$ находится виноградное дерево, слева на расстоянии $b$ - шелковица.

Какова вероятность того, что улитка доползет до виноградного дерева раньше? Сколько в среднем времени ей потребуется чтобы доползти до любого из деревьев?

Задача. Ждем 1 рубль.

Найдите $\E(T)$


Задача. Войны Добра и Зла \cite{stirzaker:otep}, 12-13

Изначально воюют один воин Добра и один воин Зла. Судьба выбирает одного из воюющих наугад и добавляет еще одного воина той же стороны. Пусть $T$ - время, когда Судьба впервые добавит война Добра. Найдите $\E(\frac{T}{T+2})$


Войны Добра и Зла. (Взято из  Kingman, Martingales in the OK Corral)

На одном холме выстроились $d$ войнов Добра, а на другом - столько же войнов Зла. Обычные стрелы не долетают, слишком велико расстояние. Но каждый день Судьба выбирает одного из всех войнов наугад и вкладывает в его колчан Золотую Стрелу. Золотая стрела бьет без промаха. Великая Битва длится покуда одна из сторон не будет полностью побеждена. Пусть случайная величина $S$ - количество выживших в этой Битве. Обозначим, $X_{t}$ и $Y_{t}$ - количество войнов Добра и Зла в конце дня $t$.  Разберитесь с асимптотикой $\E(S^{4})$ при $d\to\infty$. Подсказка: может быть найдется функция $f$ такая, что $f(X_{t},Y_{t})$ - мартингал?

Решение.

Из того, что $f(X_{t},Y_{t})$ - мартингал получаем:
\begin{equation}
f(m,n)=\frac{n}{n+m}f(m-1,n)+\frac{m}{n+m}f(m,n-1)
\end{equation}

У этого уравнения куча решений, поищем чего-нибудь простое\ldots  Попробуем многочлены невысокой степени\ldots  Находим, $f(m,n)=(m+0.5)^{2}-(n+0.5)^{2}$, $f(m,n)=(m+n+1)(m+n+2)(m+n+3(m-n)^2)$, \ldots


Если применить теорему Дуба к первому получает $0=0$, вот ко второму уже интереснее\ldots  Итак, рассматриваем мартингал
\begin{equation}
M_{t}=(X_{t}+Y_{t}+1)(X_{t}+Y_{t}+2)(X_{t}+Y_{t}+3(X_{t}-Y_{t})^{2})=(2d-t+1)(2d-t+2)(2d-t+3(X_{t}-Y_{t})^{2})
\end{equation}

Применяем к нему теорему Дуба:

\begin{equation}
(2d+1)(2d+2)2d=M_{0}=\E(M_{\tau})=\E((S+1)(S+2)(S+3S^{2}))
\end{equation}

И мы получаем, что $\E(S^{4})\sim \frac{8}{3}d^{3}$.


Задача. Банковский счет улитки. \cite{stirzaker:prp}, 12.5

Перед отправкой в свой долгий путь улитка положила все свои сбережения (один рубль) в банк. За каждую минуту банк начисляет небольшой процент $r>0$, такой что $0<r<1/cos(\frac{\pi}{a+b})-1$. Какая сумма в среднем будет находится на счету улитки к моменту достижения ей любого из деревьев?

Задача. Сумма координат улитки. \cite{stirzaker:prp}, 12.7

Каждый раз проходя через точку с координатой $x$ улитка получает $x$ рублей. Каков суммарный заработок улитки?

% Какова средняя координата? - считается ли?

Задача. Улитка на плоскости.  \cite{stirzaker:otep}, 12-17





% Задача. Улитка на склоне. (???) - уже скучновато про улитку





% название файла с коллекцией названий статей/книг

% источники:
% Ross, Second course in probability
% Stirzaker, Probability and random processes
% Stirzaker, One thousand exercises in probability
% Williams, Probability with martingales
% Morters, Martingales
% Chang, Stochastic processes
% Blom, Problems and snapshots from probability theory
% Li, Martingale Approach to the Study of Occurrence of Sequence Patterns in  Repeated % Experiments
% Winkler, Games people don't play
% Zastawniak, Basic stochastic processes
% упр. 3.12 $(-1)^{\tau}=(-1)^{K}$ без всяких ожиданий!

% Shreve, Stochastic calculus for finance I - ??? (пока не включен, а что там было?)
% aops, keys
% wilmott, ts_t






\begin{myex}
Пусть $X_{1}=1$, а далее в каждый момент времени мы делаем шаг либо вправо, либо влево. Вероятности зависят от $n$ и равны $p_{n\to n+1}=\frac{(n+1)^{2}}{n^{2}+(n+1)^{2}}$ и  $p_{n\to n-1}=\frac{n^{2}}{n^{2}+(n+1)^{2}}$. Если процесс попадает в точку ноль, то происходит Большой Взрыв. Найдите какую-нибудь $f$, чтобы $f(X_{n})$ было мартингалом. А затем посчитайте вероятность того, что когда-нибудь будет Большой Взрыв.

Решение. Для начала уточним мы будем работать с «остановленным» процессом. Т.е. будем считать, что если $X_{n}$ достиг точки $0$, то он остается равным нулю навсегда. Поэтому величина $f(0)$ не имеет никакого значения - можем выбрать как хотим. Величина $f(1)$ влияет только на математическое ожидаемое мартингала. Давайте возьмем самые простые значения $f(0)=0$ и $f(1)=1$. Хотя можно было взять и другие. Если взять совсем тривиальные $f(0)=f(1)=0$, то тоже получится мартингал, но он будет скучным, $M_{n}:=0$.

Т.к. $f(X_{n})$ - это мартингал, то получаем следующее рекуррентное соотношение:
\begin{equation}
f(n)=p_{n\to n-1} f(n-1)+p_{n\to n+1} f(n+1)
\end{equation}

Из этого соотношения и из начальных условий получаем, $f(k)=\sum_{i=1}^{k}\frac{1}{i^{2}}$.

Чему равна вероятность когда-нибудь вернуться в 0? Давайте найдем вероятность достигнуть точки $0$ раньше, чем точки $n$, $\P(\tau_{0}<\tau_{n})$. Здесь $\tau_{i}$ - момент времени, когда впервые достигнута точка $i$, если точка $0$ оказалась достигнута раньше точки $i$ и процесс «залип» в нуле, то считаем, что $\tau_{i}=\infty$.

Для нахождения этой вероятности применим теорему Дуба. Получаем, что для любого $i$:
\begin{equation}
f(1)=M_{1}=\E(M_{1})=\E(M_{\tau_{i}})=\P(\tau_{i}<\tau_{0})f(n)+\P(\tau_{i}>\tau_{0})f(0)
\end{equation}

Проверка, что теорема Дуба работает\ldots

Из этого уравнения находим, что $\P(\tau_{n}<\tau_{0})=\frac{f(1)-f(0)}{f(n)-f(0)}$

В связи с нашим выбором $f(0)=0$ и $f(1)=1$ получаем: $\P(\tau_{n}<\tau_{0})=\frac{1}{\sum_{i=1}^{n}\frac{1}{i^{2}}}$

Если большой взрыв происходит за конечное время, то какие-то точки на прямой остаются непосещенными. Значит событие $B=\{$Большой Взрыв когда-нибудь произойдет$\}$ можно представить в виде $B=\cap_{n=1}^{\infty}\{\tau_{n}<\tau_{0}\}$. Поскольку эта последовательность событий монотонна, то в силу непрерывности вероятности (\ldots ) получаем: $\P(B)=\lim_{n\to\infty}\P(\tau_{n}<\tau_{0})=\frac{1}{\sum_{i=1}^{\infty}\frac{1}{i^{2}}}$.

Как известно знатокам, $\sum_{i=1}^{\infty}\frac{1}{i^{2}}=\frac{\pi^{2}}{6}$, а кто не в курсе - читает вики \url{http://en.wikipedia.org/wiki/Basel_problem}. Следовательно,
$\P(B)=\frac{6}{\pi^{2}}$.

\end{myex}


\begin{myex}


\end{myex}




\subsection{Мартингалы сходятся}

\subsection{Еще задачи}


\Closesolutionfile{solution_file}
