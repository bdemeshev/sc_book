\Opensolutionfile{solution_file}[sols_chap_14]
% в квадратных скобках фактическое имя файла

\section{Интеграл Ито и лемма Ито}

\subsection{Интуиция и интеграл Ито для простых функций}
Многие знают геометрический смысл обычного интеграла $\int_{0}^{t}f(x)dx$ - это площадь под кривой $f(x)$ на участке от $[0;t]$. Отдельные лица даже знают физический смысл обычного интеграла, $\int_{0}^{t}f(x)dx$ - это расстояние пройденной машиной за промежуток времени $[0;t]$, если она будет двигаться со скоростью $f(x)$.

А какой смысл можно придать  $\int_{0}^{t}q(x)dp(x)$? Многие студенты прекрасно считают интегралы такого типа. Вряд ли кто затруднится посчитать что-то типа $\int_{0}^{1}cos(x^{2})d(x^{2})$. Настала пора раскрыть экономический смысл интеграла! А именно: $\int_{0}^{T}q(t)dp(t)$ - это прибыль инвестора, если: \par
Цена акции в момент времени $t$ задается функцией $p(t)$ \par
Количество акций в момент времени $t$ на руках у инвестора задается функцией $q(t)$ \par

Ровно точно такой же смысл у интеграла-Ито. Интеграл $\int_{0}^{T}s(t)dW(t)$ - это чистая прибыль инвестора за период $[0;T]$, если в момент времени $t$ у него в наличии было $s(t)$ акций, которые стоили $W_{t}$. \par

Для возрастающих функций можно предложить еще одну геометрическую интерепретацию\ldots
Площадь под линией $(p(t),q(t))$ - тут есть некоторая сложность $W(t)$ запросто может убывать, но эта мысль не повредит


Даже не зная формального определения, уже можно считать простейшие интегралы Ито. Единственное предостережение: функция $s$ предполагается непрерывной слева. Представить себе это можно так: в момент времени $t$, когда у меня на руках $s(t)$ акций я принимаю решение о покупке (продаже) и в любой момент времени $(t+\varepsilon)$ у меня уже новое количество акций, $s(t+\varepsilon)$. Новые акции я покупал (продавал) по цене $W_{t}$. При интегрировании по броуновскому движению можно было бы взять и $s(t)$ непрерывную справа - это ничего бы не изменило, т.к. броуновское движение непрерывно, однако при обобщении интеграла Ито в (\ldots ) это окажется важно.

\begin{myex} Например, Вася руководствуется следующей стратегией: купить в момент времени $t=0$ одну акцию, в момент времени $t=1$ докупить еще одну акцию, если они будут стоить меньше 5 рублей. Найдите его чистую прибыль к моменту времени $T=3$. В данном случае $s(t,W_{t})=\left\{ \right.$. Вася получит прибыль $W_{3}-W_{0}$ с первой акции и $W_{3}-W_{1}$ со второй акции (если он ее купит, т.е. если $W_{1}<5$), а значит $\int_{0}^{3}s(t,W_{t})dW(t)=(W_{3}-W_{0})+1_{W_{1}<5}(W_{3}-W{1})$.
\end{myex}

Если покупка-продажа акций идет непрерывно, то необходимо заменить ее на частую покупку-продажу и переходить к пределам. Для интеграла Ито используется предел в смысле $L^{2}$.

\begin{myex} Попробуем посчитать $\int_{0}^{T}WdW$, то есть в момент $t$ мы держим на руках столько акций, сколько они сейчас стоят.

Разобъем интервал $[0;T]$ на $n$ равных частей, посчитаем интеграл Ито, а затем устремим $n$ к бесконечности.
Обозначаем для краткости: $W_{i}=W(i\cdot \frac{T}{n})$ и $\Delta W_{i}=W_{i}-W_{i-1}$.

Сразу после момента времени $(i-1)\cdot \frac{T}{n}$ у нас на руках $W_{i-1}$ акций, а сразу после момента времени $i\cdot \frac{T}{n}$ должно быть $W_{i}$ акций. Значит в момент времени $t=i\cdot \frac{T}{n}$, когда акции стоят $W_{i}$ рублей, мы будет докупать $W_{i}-W_{i-1}$ акций. Таким образом после докупки у нас будет как раз $W_{i}$ акций. \par
В конце у нас будет $W_{n}$ акций и мы их продадим по $W_{n}$ рублей. \par
Наша прибыль составит выручка от продаж в конце минус расходы на все закупки: $W_{n}^{2}-\sum_{i=1}^{n}W_{i}\Delta W_{i}$ \par
Заметим, что $\sum_{i=1}^{n}(\Delta W_{i})^{2}=\sum_{i=1}^{n}(W_{i}^{2}+W_{i-1}^{2}-W_{i}W_{i-1}-W_{i}W_{i-1})=\sum_{i=1}^{n}(W_{i}^{2}+W_{i}^{2}-W_{i}W_{i-1}-W_{i}W_{i-1})-W_{n}^{2}=2\sum_{i=1}^{n}W_{i}\Delta W_{i}-W_{n}^{2}$ \par
Т.е. интересующую нас прибыль можно представить как $\frac{W_{n}^{2}}{2}-\frac{1}{2}\sum_{i=1}^{n}(\Delta W_{i})^{2}$ \par
В (\ldots ) мы доказали, что $\sum_{i=1}^{n}(\Delta W_{i})^{2}\to t$ в $L^{2}$ при $n\to\infty$ \par
А это значит, что $\int_{0}^{T}WdW=\frac{W(T)^{2}}{2}-\frac{t}{2}$ \par
\end{myex}


Вот стохастический анализ - это о том, как брать такие интегралы. И какими свойствами они обладают. Можно и такую аналогию провести. Обычный матанализ изучает функции, у которых существует производная, т.е. функции, локально похожие на прямую. Роль самой простой функции («прямой») в стохастическом анализе выполняет броуновское движение. Стохан изучает диффузии - случайные процессы локально похожие на броуновское движение.


Настала пора для формального определения. Мы построим интеграл Ито пошагово, как строили интеграл Лебега.

Наша цель - определить интеграл для достаточно широкого класса случайных процессов:

\begin{mydef} Пусть задано броуновское движение $W_{t}$ и $\F_{t}$ - его естественная фильтрация. Пусть $T$ - фиксированный момент времени. Обозначим с помощью $\mathcal{H}^{2}[0;T]$ множество процессов, удовлетворяющих трем условиям:

H1. Процесс $X_{t}$ адаптирован к фильтрации $\F_{t}$

H2. Процесс $X_{t}$ измерим

H3. $\E(\int_{0}^{T}X_{t}^{2}dt)<\infty$
\end{mydef}
Но начнем мы с более узкого класса, с \indef{простых} случайных процессов:

\begin{mydef} Пусть задано броуновское движение $W_{t}$ и $\F_{t}$ - его естественная фильтрация. Пусть $T$ - фиксированный момент времени. Назовем \indef{простыми} и обозначим с помощью $\mathcal{H}_{0}^{2}[0;T]$ множество процессов, удовлетворяющих условиям:

H01. Процесс $X_{t}\in\mathcal{H}^{2}[0;T]$

H02. Процесс $X_{t}$ представим в виде $X_{t}=\sum_{0}^{n-1}A_{i}1_{t\in(t_{i};t_{i+1}]}$, где $t_{i}$ - константы, удовлетворяющие условию $0=t_{0}<t_{1}<\ldots <t_{n}=T$, а $A_{i}$ - $\F_{t_{i}}$-измеримые случайные величины.
\end{mydef}
\begin{myex}
\end{myex}


Комментарий: из H02 всегда следует H1, H2(?).

\begin{mydef} Для \indef{простых} процессов назовем \indef{интегралом Ито} случайную величину, определяемую по формуле:

$\int_{0}^{T}X_{t}dW_{t}:=\sum_{i=0}^{n-1}A_{i}(W(t_{i})-W(t_{i}))$.
\end{mydef}
Строго говоря, нужно убедиться, что определение корректно, а именно, что если один и тот же простой процесс имеет два разных представления, то использование любого из них приводит к одному и тому же результату. Это небольшое упражнение (\ldots )

\begin{myth} Для простых случайных процессов интеграл Ито обладает свойствами:

PH01. $\int_{0}^{T}aX_{t}dW_{t}=a\int_{0}^{T}X_{t}dW_{t}$.

PH02. $\int_{0}^{T}(X_{t}+Y_{t})dW_{t}=\int_{0}^{T}X_{t}dW_{t}+\int_{0}^{T}Y_{t}dW_{t}$.

PH03. Изометрия Ито. $E\left((\int_{0}^{T}X_{t}dW_{t})^{2}\right)=E\int_{0}^{T}X_{t}^{2}dt$
\end{myth}
В доказательствах мы для краткости будем использовать обозначение $I(X(t))$ вместо $\int_{0}^{T}X(t)dW(t)$.

\begin{proof}
PH01. Сравнив обе части выражения видим, что они равны:

Левая: $\int_{0}^{T}aX_{t}dW_{t}=\sum_{i=0}^{n-1}aA_{i}(W(t_{i+1})-W(t_{i}))$.

Правая: $a\int_{0}^{T}X_{t}dW_{t}=a\sum_{i=0}^{n-1}A_{i}(W(t_{i+1})-W(t_{i}))$.

PH02. Как-то тавтологично даже. Возьмем  $0=t_{0}<t_{1}<\ldots <t_{n}=T$, с помощью которого можно представить оба процесса. Заметим, что если $X_{t}$ представим в виде $X_{t}=\sum_{i=0}^{n-1}A_{i}1_{t\in(t_{i};t_{i+1}]}$, а $Y_{t}$ представим в виде $Y_{t}=\sum_{i=0}^{n-1}B_{i}1_{t\in(t_{i};t_{i+1}]}$, то процесс $X_{t}+Y_{t}$ представим в виде: $\sum_{i=0}^{n-1}(A_{i}+B_{i})1_{t\in(t_{i};t_{i+1}]}$. А теперь сравним:

Левая: $\sum_{i=0}^{n-1}(A_{i}+B_{i})(W(t_{i+1})-W(t_{i}))$

Правая: $\sum_{i=0}^{n-1}A_{i}(W(t_{i+1})-W(t_{i}))+\sum_{i=0}^{n-1}B_{i}(W(t_{i+1})-W(t_{i}))$

PH03. Снова сравним обе части:

Левая. Шаг 1. $(\int_{0}^{T}X_{t}dW_{t})^{2}=\sum_{i,j}A_{i}A_{j}(W(t_{i+1})-W(t_{i}))(W(t_{j+1})-W(t_{j}))$. Если взять $i\neq j$, например, $i<j$, то сомножитель $(W(t_{j+1})-W(t_{j}))$ не зависит от остальных сомножителей. Остальные сомножители являются $\F_{t_{j}}$ - измеримыми, а $(W(t_{j+1})-W(t_{j}))$ не зависит \s-алгебры $\F_{t_{j}}$. Значит при $i\neq j$ ожидание $\E(A_{i}A_{j}(W(t_{i+1})-W(t_{i}))(W(t_{j+1})-W(t_{j})))=\E(\ldots )\E(W(t_{j+1})-W(t_{j}))=(\ldots )\cdot 0=0$.

Шаг 2. После шага 1 от всей суммы осталось только: $\sum_{i}A_{i}^{2}(W(t_{i+1})-W(t_{i}))^{2}$. Замечаем, что $A_{i}^{2}$ не зависит от $(W(t_{i+1})-W(t_{i}))^{2}$, т.к. $A_{i}^{2}$ - это $\F_{t_{i}}$-измеримая случайная величина. И, наконец, $\E((\int_{0}^{T}X_{t}dW_{t})^{2})=\E(\sum_{i}A_{i}^{2}(W(t_{i+1})-W(t_{i}))^{2})=\sum_{i}\E(A_{i}^{2})\E(W(t_{i+1})-W(t_{i}))^{2})=\sum_{i}\E(A_{i}^{2})(t_{i+1}-t_{i})$.

Правая. С правой проще. Заметив, что $X_{t}^{2}=\sum_{i=0}^{n-1}A_{i}^{2}1_{t\in(t_{i};t_{i+1}]}$ (при $i\neq j$ произведение индикаторов обнуляется), получаем, что $\E(\int_{0}^{T}X_{t}^{2}dt)=\sum_{i=0}^{n-1}\E(A_{i}^{2})(t_{i+1}-t_{i})$.
\end{proof}

\subsection{Интеграл Ито для аш2}

Итак, интеграл Ито определен для процессов из $\mathcal{H}_{0}[0;T]$. Как расширить его на процессы из $\mathcal{H}[0;T]$?

Идея нового, более широкого, определения проста:

Каждый процесс $X(t)$ из $\mathcal{H}[0;T]$ является пределом некоей последовательности простых процессов из $\mathcal{H}_{0}[0;T]$. Для каждого простого процесса $X_{n}(t)$ интеграл Ито определен и является случайной величиной, обозначим ее $I_{n}$. Оказывается, что последовательность интегралов Ито $I_{n}$ всегда сходится в пространстве $L^{2}(\Omega)$ к некоторой случайной величине $I$. И этот предел $I$ не зависит от выбора последовательности простых процессов $X_{n}(t)$, сходящейся к $X(t)$. Этот предел $I$ мы и назовем интегралом Ито для процесса $X_{t}$.

Сразу следует заметить, что интеграл Ито определен как предел в смысле $L^{2}(\Omega)$, поэтому единственности в поточечном смысле мы гарантировать не сможем. Интеграл Ито в $\mathcal{H}^{2}[0;T]$ определен с точностью до множества меры нуль. Несколько случайных величины равных почти наверное могут представлять один и тот же интеграл Ито. теперь все утверждения касающиеся Интеграла Ито будут формулироваться с припиской «почти наверное».


Формальное определение выглядит так:

\begin{mydef} Пусть $X(t)\in\mathcal{H}^{2}[0;T]$ и $X_{n}(t)$ произвольная последовательность простых процессов, сходящаяся к процессу $X(t)$ в $L^{2}(\Omega\times\R)$. Пусть последовательность случайных величин $I(X_{n}(t))$ сходится в $L^{2}(\Omega)$  к случайной величине $I$. Интегралом Ито случайного процесса $X(t)$ называется случайная величина $I$, обозначается она как $\int_{0}^{T}X(t)dW(t)$.
\end{mydef}
Корректность определения подкрепляют 3 «кита»:

\begin{myth} Множество $\mathcal{H}_{0}^{2}[0;T]$ плотно в $\mathcal{H}^{2}[0;T]$. Для любого процесса $X(t)\in\mathcal{H}^{2}$ существует последовательность $X_{n}(t)\in\mathcal{H}_{0}^{2}[0;T]$, такая что $||X_{n}(t)-X(t)||_{L^{2}(\Omega \times \R)}\to 0$.
\end{myth}
\begin{proof} Доказательство кита отложим до (\ldots )
\end{proof}
\begin{myth} Если есть последовательность простых процессов $X_{n}(t)\in\mathcal{H}_{0}^{2}[0;T]$ сходится к процессу $X_{t}$, т.е. $||X_{n}(t)-X(t)||_{L^{2}(\Omega \times \R)}\to 0$, то последовательность $I_{n}=\int_{0}^{T}X_{t}^{(n)}dW_{t}$ сходится к некоторой случайной величине $I$ в $L^{2}(\Omega)$.
\end{myth}
\begin{proof} Шаг 1. Последовательность $(X_{n}(t)-X(t))$ сходится к нулю в $L^{2}(\Omega \times \R)$, значит $X_{n}(t)$ - это последовательность Коши. Действительно, $||X_{i}(t)-X_{j}(t)||=||X_{i}(t)-X(t)+X(t)-X_{j}(t)||\leq ||X_{i}(t)-X(t)||+||X(t)-X_{j}(t)||$. Для любого $\varepsilon>0$, можно выбрать такое $N$, начиная с которого, т.е. при $i>N$ и $j>N$ оба слагаемых будут меньше $\varepsilon/2$.

Шаг 2. Последовательность $X_{n}(t)$ - это последовательность Коши в $L^{2}(\Omega\times\R)$. В силу изометрии Ито последовательность $I_{n}=\int_{0}^{T}X_{n}(t)dW(t)$ также будет последовательностью Коши в $L^{2}(\Omega)$. Подробнее. Процесс $Z(t)=X_{i}(t)-X_{j}(t)$ является простым, поэтому $||Z(t)||_{L^{2}(\Omega \times \R)}=||\int_{0}^{T}Z(t)dW(t)||_{L^{2}(\Omega)}$. Кроме того, $\int_{0}^{T}Z(t)dW(t)=\int_{0}^{T}X_{i}(t)dW(t)-\int_{0}^{T}X_{j}(t)dW(t)=I_{i}-I_{j}$. Значит $||X_{i}(t)-X_{j}(t)||_{L^{2}(\Omega \times \R)}=||I_{i}-I_{j}||_{L^{2}(\Omega)}$.

Шаг 3. Пространство $L^{2}(\Omega)$ полное, поэтому любая последовательность Коши $I_{n}$ сходится к некоторой случайной величине $I$.
\end{proof}

\begin{myth} Если две различные последовательности процессов $X_{n}(t)$ и $Y_{n}(t)$ сходятся в $L^{2}(\Omega\times \R)$ к одному пределу $X(t)$, то и последовательность интегралов Ито, $I(X_{n}(t))$ и $I(Y_{n}(t))$ сходятся к одному пределу в $L^{2}(\Omega)$.
\end{myth}
\begin{proof} Шаг 1. Заметим, что разница $||X_{n}(t)-Y_{n}(t)||$ cходится к нулю в силу неравенства треугольника: $||X_{n}(t)-Y_{n}(t)||=||X_{n}(t)-X(t)+X(t)-Y_{n}(t)||\leq ||X_{n}(t)-X(t)||+||X(t)-Y_{n}(t)||$. В этой сумме каждое слагаемое стремится к нулю с ростом $n$.

Шаг 2. В силу изометрии Ито, $||X_{n}(t)-Y_{n}(t)||=||I(X_{n}(t)-I(Y_{n}(t))||_{L^{2}(\Omega)}$. Значит последовательность $||I(X_{n})-I(Y_{n})||$ стремится к нулю.

Шаг 3. В силу теоремы (\ldots ) последовательность $I(X_{n}(t))$ сходится к некоей случайной величине $I$. Используем неравенство треугольника еще раз, $||I(Y_{n}(t))-I||=||I(Y_{n}(t))-I(X_{n}(t))+I(X_{n}(t))-I||\leq ||I(Y_{n}(t))-I(X_{n}(t))||+||I(X_{n}(t))-I||$. Оба слагаемых стремятся к нулю, первое в силу шага 2, второе в силу сходимости $I(X_{n}(t))$. Значит $I(Y_{n}(t))$ стремится к той же случайной величине $I$.
\end{proof}

теперь интеграл Ито корректно определен для случайных величин из $\mathcal{H}^{2}[0;T]$! Попутно заметим, что для простых процессов новое определение совпадает со старым, т.к. в качестве последовательности сходящейся к простому процессу $X(t)$ можно взять последовательность $X(t)$, $X(t)$, $X(t)$,\ldots  Поэтому можно использовать одно и то же обозначение для интеграла Ито на $\mathcal{H}^{2}[0;T]$ и на $\mathcal{H}_{0}^{2}[0;T]$

Интеграл Ито снова обладает хорошими свойствами:

\begin{myth} Для случайных процессов из $\mathcal{H}^{2}[0;T]$ интеграл Ито обладает свойствами:

PH1. $\int_{0}^{T}aX(t)dW(t)=a\int_{0}^{T}X(t)dW(t)$ (почти наверное).

PH2. $\int_{0}^{T}(X_{t}+Y_{t})dW_{t}=\int_{0}^{T}X_{t}dW_{t}+\int_{0}^{T}Y_{t}dW_{t}$ (почти наверное).

PH3. Изометрия Ито. $E\left((\int_{0}^{T}X_{t}dW_{t})^{2}\right)=E\int_{0}^{T}X_{t}^{2}dt$

PH4. Условная изометрия Ито.
\end{myth}
\begin{proof}

PH1. Берем последовательность $X_{n}(t)$, сходящуюся к $X(t)$, автоматически оказывается, что $aX_{n}(t)$ сходится к $aX(t)$, обе сходимости, конечно, в $L^{2}(\Omega\times \R)$. Но для простых процессов свойство PH01 доказано, значит $I(aX_{n}(t))=aI(X_{n}(t))$. Последовательность $I(aX_{n}(t))$ сходится к $I(aX(t))$, а последовательность $aI(X_{n}(t))$ сходится к $aI(X(t))$, на этот раз обе сходимости в $L^{2}(\Omega)$. Значит $I(aX(t))$ и $aI(X(t))$ равны почти наверное.

PH2. Берем последовательность $X_{n}(t)$, сходящуюся в $L^{2}(\Omega\times\R)$ к процессу $X(t)$ и последовательность $Y_{n}(t)$, сходящуюся в $L^{2}(\Omega\times\R)$ к процессу $Y(t)$. Последовательность $X_{n}(t)+Y_{n}(t)$ будет сходится к $X(t)+Y(t)$. Для простых процессов свойство PH02 доказано, значит $I(X_{n}(t)+Y_{n}(t))=I(X_{n}(t))+I(Y_{n}(t))$. По определению, предел последовательности $I(X_{n}(t))$ равен $I(X(t))$, предел последовательности $I(Y_{n}(t))$ равен $I(Y(t))$, а предел последовательности $I(X_{n}(t)+Y_{n}(t))$ равен $I(X(t)+Y(t))$. Значит $I(X(t)+Y(t))=I(X(t))+I(Y(t))$.

PH3. Существует последовательность простых процессов $X_{n}(t)$, сходящаяся к $X(t)$. Применяем к каждому ее члену изометрию Ито (доказанную для простых процессов: $||X_{n}(t)||_{L^{2}(\Omega\times\R)}=||I(X_{n}(t))||_{L^{2}(\Omega)}$. Последовательность процессов $X_{n}(t)$ сходится в $L^{2}(\Omega\times\R)$ к $X(t)$, а значит $||X_{n}(t)||\to ||X(t)||$. Последовательность случайных величин $I(X_{n}(t))$ сходится в $L^{2}(\Omega)$ к $I(X(t))$, а значит $||I(X_{n}(t))||\to ||I(X(t))||$. И, следовательно, $||I(X(t))||=||X(t)||$.
\end{proof}

\subsection{Интеграл Ито как процесс}


\subsection{Ito's lemma}

Почему когда я происходил от обезьяны меня не предупредили, что придется учить доказательство леммы Ито?

Когда надо посчитать обычный интеграл типа $\int_{0}^{T}\cos(3x+7)dx$, никто не будет считать его как предел сумм. Обычно пользуются теоремой Ньютона-Лейбница, знанием производных основных функций и свойствами производной. Аналогично и в стохастическом анализе. В тех редких случаях когда стохастический интеграл можно посчитать в явном виде, для подсчета обычно хватает леммы Ито и понимание смысла краткой записи.

Лемма Ито в краткой записи:
\begin{myth}

\end{myth}

Лемма Ито в полной записи:
\begin{myth}

\end{myth}



\subsection{Использование процесса Ито при моделировании }
Данный раздел списан с источника \cite{lones:dtc}

Допустим у нас есть некий процесс $Y_{t}$, поведение которого без случайных шоков описывается обыкновенным дифференциальным уравнением $dY=f(t,Y)dt$.

Для описания шоков предположим, что время поделено на маленькие отрезочки длины $1/n$. И на каждом отрезке может с вероятностью $O(1/n)$ произойти случайный шок, который превращает $Y_{t}$ в $(1+O(1/n))Y_{t}$.

Оказывается, что в этом случае процесс $Y_{t}$ хорошо описывается с помощью процесса Ито.

Рассмотрим пару конкретных примеров.

(lones)


(steele, exam)

\url{http://math.stackexchange.com/questions/284874/why-do-people-simulate-with-brownian-motion-instead-of-intuitive-brownian-motio}



\begin{mydef}
Процессом Ито называется случайный процесс представимый в виде:

\end{mydef}

Функция










\subsection{Еще задачи}


\begin{problem}
Пусть $dX=udt+vdW$, где $u$ и $v$ - не обязательно константы. Пусть $Y_{t}=\int_{0}^{t}X_{a}da$. Найдите $dY_{t}$.
\begin{sol}
$X_{t}dt$
\end{sol}
\end{problem}


\Closesolutionfile{solution_file}
